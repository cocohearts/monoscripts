{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "47cd59de",
      "metadata": {
        "id": "47cd59de"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch import Tensor\n",
        "from typing import Tuple, Union, Optional, List\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "from tqdm.notebook import tqdm\n",
        "from typing import Callable\n",
        "from jaxtyping import Float, Int\n",
        "import einops\n",
        "from dataclasses import dataclass\n",
        "from torch.utils.data import DataLoader\n",
        "from accelerate import Accelerator\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "from accelerate import Accelerator, DistributedDataParallelKwargs, notebook_launcher\n",
        "from torch.profiler import profile, record_function, ProfilerActivity"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "ccce54a1",
      "metadata": {},
      "outputs": [],
      "source": [
        "import dotenv\n",
        "from datasets import load_dataset\n",
        "from transformers import AutoTokenizer\n",
        "import os\n",
        "dotenv.load_dotenv()\n",
        "import huggingface_hub\n",
        "HUGGINGFACE_API_KEY = os.getenv(\"HUGGINGFACE_API_KEY\")\n",
        "huggingface_hub.login(token=HUGGINGFACE_API_KEY)\n",
        "\n",
        "# Login using e.g. `huggingface-cli login` to access this dataset\n",
        "# ds = load_dataset(\"bigcode/the-stack-v2\", cache_dir=\"/shared/alex-zhao-storage/the-stack-v2\", split=\"train\")\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\", cache_dir=\"/shared/alex-zhao-storage/hf-cache\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "4e764d0e",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "30522"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "tokenizer.vocab_size"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "baab5229",
      "metadata": {
        "id": "baab5229"
      },
      "outputs": [],
      "source": [
        "device = torch.device(\"cuda\")\n",
        "\n",
        "# a utility for calculating running average\n",
        "class AverageMeter():\n",
        "    def __init__(self):\n",
        "        self.num = 0\n",
        "        self.tot = 0\n",
        "\n",
        "    def update(self, val: float, sz: float):\n",
        "        self.num += val*sz\n",
        "        self.tot += sz\n",
        "\n",
        "    def calculate(self) -> float:\n",
        "        return self.num/self.tot"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "88556b9a",
      "metadata": {},
      "source": [
        "# Prefix Ops"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "5646f2f6",
      "metadata": {},
      "outputs": [],
      "source": [
        "from math import log2\n",
        "class PrefixOps():\n",
        "    # Assumes that position is a power of 2\n",
        "    def pref_mul(t: Float[Tensor, \"batch position d_model d_state\"]):\n",
        "        n_layers = int(log2(t.shape[1]))\n",
        "        up_tensors = []\n",
        "        down_tensors = []\n",
        "        up_tensors.append(t)\n",
        "        for _ in range(n_layers):\n",
        "            left = up_tensors[-1][:, ::2]\n",
        "            right = up_tensors[-1][:, 1::2]\n",
        "            up_tensors.append(left * right)\n",
        "\n",
        "        down_tensors.append(torch.ones_like(up_tensors[-1]))\n",
        "        for index in range(n_layers):\n",
        "            new = torch.zeros_like(up_tensors[-2 - index])\n",
        "            new[:, ::2] = down_tensors[-1]\n",
        "            new[:, 1::2] = down_tensors[-1] * up_tensors[-2 - index][:, ::2]\n",
        "            down_tensors.append(new)\n",
        "        return down_tensors[-1] * t\n",
        "\n",
        "    def pref_add(t: Float[Tensor, \"batch position d_model d_state\"]):\n",
        "        n_layers = int(log2(t.shape[1]))\n",
        "        up_tensors = []\n",
        "        down_tensors = []\n",
        "        up_tensors.append(t)\n",
        "        for _ in range(n_layers):\n",
        "            left = up_tensors[-1][:, ::2]\n",
        "            right = up_tensors[-1][:, 1::2]\n",
        "            up_tensors.append(left + right)\n",
        "\n",
        "        down_tensors.append(torch.zeros_like(up_tensors[-1]))\n",
        "        for index in range(n_layers):\n",
        "            new = torch.zeros_like(up_tensors[-2 - index])\n",
        "            new[:, ::2] = down_tensors[-1]\n",
        "            new[:, 1::2] = down_tensors[-1] + up_tensors[-2 - index][:, ::2]\n",
        "            down_tensors.append(new)\n",
        "        return down_tensors[-1] + t\n",
        "\n",
        "class TestPrefixOps():\n",
        "    def __init__(self, batch, position, d_model, d_state):\n",
        "        self.batch = batch\n",
        "        self.position = position\n",
        "        self.d_model = d_model\n",
        "        self.d_state = d_state\n",
        "\n",
        "    def pref_mul(self):\n",
        "        my_in = torch.exp(torch.randn(self.batch, self.position, self.d_model, self.d_state))\n",
        "        my_out = PrefixOps.pref_mul(my_in)\n",
        "        true_out = torch.ones_like(my_in)\n",
        "        for i in range(self.position):\n",
        "            if i==0:\n",
        "                true_out[:, i] = my_in[:, i]\n",
        "            else:\n",
        "                true_out[:, i] = true_out[:, i-1] * my_in[:, i]\n",
        "        assert(torch.allclose(my_out, true_out))\n",
        "    \n",
        "    def pref_add(self):\n",
        "        my_in = torch.randn(self.batch, self.position, self.d_model, self.d_state)\n",
        "        my_out = PrefixOps.pref_add(my_in)\n",
        "        true_out = torch.zeros_like(my_in)\n",
        "        for i in range(self.position):\n",
        "            if i==0:\n",
        "                true_out[:, i] = my_in[:, i]\n",
        "            else:\n",
        "                true_out[:, i] = true_out[:, i-1] + my_in[:, i]\n",
        "        assert(torch.allclose(my_out, true_out, atol=1e-4))\n",
        "\n",
        "TestPrefixOps(12, 64, 768, 64).pref_mul()\n",
        "TestPrefixOps(12, 64, 768, 64).pref_add()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6eb743ee",
      "metadata": {
        "id": "6eb743ee"
      },
      "source": [
        "# Implement Mamba"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e6cffe0a",
      "metadata": {
        "id": "e6cffe0a"
      },
      "source": [
        "## Single Head"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "5ZVRz_LHQNHo",
      "metadata": {
        "id": "5ZVRz_LHQNHo"
      },
      "outputs": [],
      "source": [
        "# TODO: generate not supported for pref_sum\n",
        "test_ssm_ablation = False\n",
        "pref_sum = True\n",
        "use_double = False\n",
        "careful_double = True\n",
        "\n",
        "class SSM(nn.Module):\n",
        "    def __init__(self, d_model, d_state):\n",
        "        super().__init__()\n",
        "\n",
        "        # get A by negative softplus\n",
        "        self.Araw = nn.Parameter(torch.randn(d_model, d_state))\n",
        "        torch.nn.init.kaiming_normal_(self.Araw)\n",
        "        self.Araw.data = self.Araw.data.clamp(min=-4)\n",
        "        self.s_B = nn.Linear(d_model, d_state)\n",
        "        self.s_C = nn.Linear(d_model, d_state)\n",
        "        self.s_D = nn.Linear(d_model, 1)\n",
        "        self.P = nn.Parameter(torch.randn(d_model))\n",
        "        # torch.nn.init.xavier_normal_(self.P)\n",
        "\n",
        "        self.d_model = d_model\n",
        "        self.d_state = d_state\n",
        "\n",
        "    def forward(self, x: Float[Tensor, \"batch position d_model\"], keep_hidden=False, use_hidden=False) -> Float[Tensor, \"batch position d_model\"]:\n",
        "        sp = nn.Softplus()\n",
        "        disc = sp(self.P + self.s_D(x).repeat(1, 1, self.d_model)) # size batch position d_model\n",
        "        A = -1 * sp(self.Araw)\n",
        "        A_bar_pre = disc[..., None] * A # size batch position d_model d_state\n",
        "        # A_bar_pre = torch.where(torch.abs(A_bar_pre) < 1e-4, -1e-4 * torch.ones_like(A_bar_pre), A_bar_pre)\n",
        "        A_bar = torch.exp(A_bar_pre)\n",
        "        B = self.s_B(x) # size batch position d_state\n",
        "        # ratio = 1 + A_bar_pre/2 + A_bar_pre**2/2 + A_bar_pre**3/6 + A_bar_pre**4/24 + A_bar_pre**5/120\n",
        "        B_bar = B[:, :, None] / A * (A_bar - 1)\n",
        "\n",
        "        C = self.s_C(x)\n",
        "\n",
        "        assert(str(x.device)[:4] == 'cuda')\n",
        "\n",
        "        if pref_sum:\n",
        "            Bx = B_bar * x[..., None]\n",
        "            Bx_log = torch.log(torch.abs(Bx))\n",
        "            A_bar_prod_log = PrefixOps.pref_add(A_bar_pre)\n",
        "            # AinvsB_log must be at most 77\n",
        "            if use_double:\n",
        "                A_bar_prod_log = torch.max(A_bar_prod_log, Bx_log-150)\n",
        "                if careful_double:\n",
        "                    A_bar_prod_log = torch.max(A_bar_prod_log, Bx_log-70)\n",
        "                AinvsB_log = Bx_log - A_bar_prod_log\n",
        "                AinvsBsum = PrefixOps.pref_add(torch.exp(AinvsB_log.to(torch.double)) * torch.sign(Bx))\n",
        "                assert(AinvsBsum.dtype == torch.double)\n",
        "                y = torch.matmul((AinvsBsum * torch.exp(A_bar_prod_log.to(torch.double))).to(torch.float), C[..., None]).squeeze(-1).to(x.dtype)\n",
        "            else:\n",
        "                A_bar_prod_log = torch.max(A_bar_prod_log, Bx_log-70)\n",
        "                AinvsB_log = Bx_log - A_bar_prod_log\n",
        "                AinvsBsum = PrefixOps.pref_add(torch.exp(AinvsB_log) * torch.sign(Bx))\n",
        "                y = torch.matmul((AinvsBsum * torch.exp(A_bar_prod_log)), C[..., None]).squeeze(-1)\n",
        "            if torch.isnan(y).any() or torch.isinf(y).any():\n",
        "                raise ValueError(\"NaN or Inf values detected in SSM output\")\n",
        "        else:\n",
        "            if use_hidden:\n",
        "                h = self.h\n",
        "            else:\n",
        "                h = torch.zeros(x.shape[0], self.d_model, self.d_state).to(x.device)\n",
        "            y = torch.zeros_like(x).to(x.device)\n",
        "            for index in range(x.shape[1]):\n",
        "                if index == 0:\n",
        "                    h = B_bar[:, index] * x[:, index].view(-1, self.d_model, 1)\n",
        "                else:\n",
        "                    h = A_bar[:, index] * h + B_bar[:, index] * x[:, index].view(-1, self.d_model, 1)\n",
        "                y[:, index] = torch.matmul(h, C[:, index, :, None]).squeeze(-1)\n",
        "\n",
        "        if torch.isnan(y).any() or torch.isinf(y).any():\n",
        "            raise ValueError(\"NaN or Inf values detected in SSM output\")\n",
        "        if keep_hidden:\n",
        "            self.h = h\n",
        "        return y\n",
        "\n",
        "    def device(self):\n",
        "        return next(self.parameters()).device\n",
        "    \n",
        "    def test_forward(self, x: Float[Tensor, \"batch position d_model\"]):\n",
        "        sp = nn.Softplus()\n",
        "        disc = sp(self.P + self.s_D(x).repeat(1, 1, self.d_model)) # size batch position d_model\n",
        "        A_bar_pre = disc[..., None] * (-1 * sp(self.Araw)) # size batch position d_model d_state\n",
        "        # A_bar_pre = torch.where(torch.abs(A_bar_pre) < 1e-4, -1e-4 * torch.ones_like(A_bar_pre), A_bar_pre)\n",
        "        A_bar = torch.exp(A_bar_pre)\n",
        "        B = self.s_B(x) # size batch position d_state\n",
        "        ratio = 1 + A_bar_pre/2 + A_bar_pre**2/2 + A_bar_pre**3/6 + A_bar_pre**4/24 + A_bar_pre**5/120\n",
        "        B_bar = ratio * (torch.unsqueeze(disc, -1) * torch.unsqueeze(B, 2)) # size batch position d_model d_state\n",
        "\n",
        "        C = self.s_C(x)\n",
        "\n",
        "        assert(str(x.device)[:4] == 'cuda')\n",
        "        h = torch.zeros(x.shape[0], self.d_model, self.d_state).to(x.device)\n",
        "\n",
        "        test_y = self.forward(x)\n",
        "\n",
        "        y = torch.zeros_like(x).to(x.device)\n",
        "        for index in range(x.shape[1]):\n",
        "            if index == 0:\n",
        "                h = B_bar[:, index] * x[:, index].view(-1, self.d_model, 1)\n",
        "            else:\n",
        "                h = A_bar[:, index] * h + B_bar[:, index] * x[:, index].view(-1, self.d_model, 1)\n",
        "            y[:, index] = torch.matmul(h, C[:, index, :, None]).squeeze(-1)\n",
        "        print(\"top 20 diff: \", (y / test_y).abs().flatten().topk(50).values)\n",
        "        twox_diff = (y / test_y).abs() > 2\n",
        "        print(\">2x diff: \", twox_diff.sum().item())\n",
        "        sixx_diff = (y / test_y).abs() > 6\n",
        "        print(\">6x diff: \", sixx_diff.sum().item())\n",
        "        print(\"6x diff output vals: \", test_y[sixx_diff].flatten())\n",
        "\n",
        "    # def inf_forward(self, x: Float[Tensor, \"d_model\"]) -> Float[Tensor, \"d_model\"]:\n",
        "    #     sp = nn.Softplus()\n",
        "    #     disc = sp(self.P + self.s_D(x).repeat(1, 1, self.d_model)) # size batch position d_model\n",
        "    #     A_bar_pre = torch.unsqueeze(disc, -1) * self.A # size batch position d_model d_state\n",
        "    #     A_bar = torch.exp(A_bar_pre)\n",
        "    #     B = self.s_B(x) # size batch position d_state\n",
        "    #     B_bar = (A_bar - 1) / A_bar_pre * (torch.unsqueeze(disc, -1) * torch.unsqueeze(B, 2)) # size batch position d_model d_state\n",
        "\n",
        "    #     C = self.s_C(x)\n",
        "\n",
        "    #     self.h = A_bar * self.h + B_bar * x\n",
        "    #     return torch.matmul(self.h, C[:, None])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "29fc4254",
      "metadata": {
        "id": "29fc4254"
      },
      "outputs": [],
      "source": [
        "class Mamba(nn.Module):\n",
        "    def __init__(self, d_model, d_state, d_conv, expand):\n",
        "        # dim: the dimension of the input\n",
        "        # n_hidden: the dimension of the keys, queries, and values\n",
        "\n",
        "        super().__init__()\n",
        "        self.d_model = d_model\n",
        "        self.d_state = d_state\n",
        "        self.d_conv = d_conv\n",
        "        self.expand = expand\n",
        "\n",
        "        d_head = expand * d_state\n",
        "        self.upscale = nn.Linear(d_model, d_head)\n",
        "        self.gate = nn.Linear(d_model, d_head)\n",
        "        self.conv = nn.Conv1d(d_head, d_head, d_conv, padding=d_conv-1, groups=d_head)\n",
        "        self.ssm = SSM(d_head, d_state)\n",
        "        self.downscale = nn.Linear(d_head, d_model)\n",
        "\n",
        "        self.silu = nn.SiLU()\n",
        "\n",
        "    def forward(self, x: Float[Tensor, \"batch position d_model\"], keep_hidden=False, use_hidden=False) -> Tuple[torch.Tensor, torch.Tensor]:\n",
        "        upscaled = self.upscale(x)\n",
        "        conv_out = self.conv(upscaled.transpose(1,2)).transpose(1,2)[:, :upscaled.shape[1]]\n",
        "        ssm_out = self.ssm(self.silu(conv_out), keep_hidden=keep_hidden, use_hidden=use_hidden)\n",
        "        gate_output = self.silu(self.gate(x))\n",
        "        final_output = self.downscale(ssm_out * gate_output)\n",
        "\n",
        "        if torch.isnan(final_output).any() or torch.isinf(final_output).any():\n",
        "            raise ValueError(\"NaN or Inf values detected in Mamba output\")\n",
        "\n",
        "        return final_output\n",
        "    \n",
        "    def generate(self, x: Float[Tensor, \"batch position d_model\"], new_tokens: int):\n",
        "        return self.forward(self.generate(x, new_tokens))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "ddd56734",
      "metadata": {
        "id": "ddd56734"
      },
      "outputs": [],
      "source": [
        "from einops import rearrange\n",
        "\n",
        "class MambaLayer(nn.Module):\n",
        "    def __init__(self, n_heads, d_model, d_state, d_conv, expand):\n",
        "        super().__init__()\n",
        "\n",
        "        self.Heads = nn.ModuleList([Mamba(d_model, d_state, d_conv, expand) for _ in range(n_heads)])\n",
        "        self.n_heads = n_heads\n",
        "        self.rms_norm = nn.RMSNorm((d_model))\n",
        "        self.out_project = nn.Linear(d_model, d_model)\n",
        "        self.layer_norm = nn.LayerNorm(d_model)\n",
        "\n",
        "    def forward(self, x: Float[Tensor, \"batch position d_model\"], keep_hidden=False, use_hidden=False) -> Float[Tensor, \"batch position d_model\"]:\n",
        "        if torch.isinf(x).any():\n",
        "            raise ValueError(\"Inf values detected in MambaLayer input\")\n",
        "        if torch.isnan(x).any():\n",
        "            raise ValueError(\"NaN values detected in MambaLayer input\")\n",
        "        normed_x = self.rms_norm(x)\n",
        "        head_outputs = torch.zeros(x.shape).to(x.device)\n",
        "        for head in self.Heads:\n",
        "            head_outputs += head(normed_x, keep_hidden=keep_hidden, use_hidden=use_hidden)\n",
        "        x = x + self.layer_norm(self.out_project(head_outputs))\n",
        "        if torch.isnan(x).any() or torch.isinf(x).any():\n",
        "            raise ValueError(\"NaN or Inf values detected in MambaLayer forward\")\n",
        "        return x\n",
        "    \n",
        "    def generate(self, x: Float[Tensor, \"batch position d_model\"], new_tokens: int):\n",
        "        normed_x = self.rms_norm(x)\n",
        "        \n",
        "        out = self.forward(normed_x, keep_hidden=True)\n",
        "        head_outputs = torch.zeros(x.shape).to(x.device)\n",
        "        for head in self.Heads:\n",
        "            head_outputs += head.generate(normed_x, new_tokens)\n",
        "        x = x + self.layer_norm(self.out_project(head_outputs))\n",
        "        if torch.isnan(x).any() or torch.isinf(x).any():\n",
        "            raise ValueError(\"NaN or Inf values detected in MambaLayer forward\")\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "vI6qu8MVqVbt",
      "metadata": {
        "id": "vI6qu8MVqVbt"
      },
      "outputs": [],
      "source": [
        "class FFN(nn.Module):\n",
        "    def __init__(self, dim: int, n_hidden: int):\n",
        "        super().__init__()\n",
        "        self.net = nn.Sequential(\n",
        "            nn.LayerNorm(dim),\n",
        "            nn.Linear(dim, n_hidden),\n",
        "            nn.GELU(),\n",
        "            nn.Linear(n_hidden, dim),\n",
        "        )\n",
        "\n",
        "    def forward(self, x: torch.Tensor)-> torch.Tensor:\n",
        "        return self.net(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "id": "ueCWqzJdqXlg",
      "metadata": {
        "id": "ueCWqzJdqXlg"
      },
      "outputs": [
        {
          "ename": "SyntaxError",
          "evalue": "f-string: expecting '}' (3523211096.py, line 51)",
          "output_type": "error",
          "traceback": [
            "\u001b[0;36m  Cell \u001b[0;32mIn[44], line 51\u001b[0;36m\u001b[0m\n\u001b[0;31m    print(f\"Gradient for {param.name} with {param.numel()} elements is {\"nan\" if torch.isnan(param.grad).any() else \"inf\"}. Zeroing out.\")\u001b[0m\n\u001b[0m                                                                         ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m f-string: expecting '}'\n"
          ]
        }
      ],
      "source": [
        "class MambaLM(nn.Module):\n",
        "    def __init__(self, vocab_size, n_layers, n_heads, d_model, d_state, d_conv, expand, context_len=1000):\n",
        "        super().__init__()\n",
        "\n",
        "        self.vocab_size = vocab_size\n",
        "        self.embedding = nn.Embedding(self.vocab_size, d_model)\n",
        "        self.embedding.weight.requires_grad = False\n",
        "        self.context_len = context_len\n",
        "\n",
        "        self.pos_embedding = nn.Embedding(context_len, d_model)\n",
        "        self.pos_embedding.weight.requires_grad = False\n",
        "        self.pos_embedding.weight.data[:, ::2] = torch.sin(torch.arange(0, context_len)[:, None] / 10000 ** (torch.arange(0, d_model, 2)[None, :] / d_model))\n",
        "        self.pos_embedding.weight.data[:, 1::2] = torch.cos(torch.arange(0, context_len)[:, None] / 10000 ** (torch.arange(1, d_model, 2)[None, :] / d_model))\n",
        "\n",
        "        self.layers = nn.ModuleList([MambaLayer(n_heads, d_model, d_state, d_conv, expand) for _ in range(n_layers)])\n",
        "        self.n_heads = n_heads\n",
        "        self.output_layer = nn.Linear(d_model, self.vocab_size)\n",
        "\n",
        "    def forward(self, x: torch.Tensor) -> Tuple[torch.Tensor, torch.Tensor]:\n",
        "        # Count zeros on left side of each sequence\n",
        "        mask = (x == 0).to(self.device())\n",
        "        left_zeros = mask.cummin(dim=1)[0].sum(dim=1, keepdim=True)\n",
        "\n",
        "        pos_embed_indices = torch.arange(x.shape[1]).expand(x.shape[0], -1).to(self.device()) - left_zeros\n",
        "        pos_embed_indices = torch.where(pos_embed_indices >= 0, pos_embed_indices, 0)\n",
        "        pos_embed = torch.where(pos_embed_indices.unsqueeze(-1) >= 0, self.pos_embedding(pos_embed_indices), 0)\n",
        "\n",
        "        x = self.embedding(x)\n",
        "        x = x + pos_embed\n",
        "        if x.isnan().any() or x.isinf().any():\n",
        "            raise ValueError(\"NaN or Inf values detected in MambaLM input\")\n",
        "        for layer in self.layers:\n",
        "            x = layer(x)\n",
        "        x = self.output_layer(x)\n",
        "        return x\n",
        "    \n",
        "    def train_step(self, x: Int[Tensor, \"batch position\"], optimizer, scheduler, accelerator) -> Tuple[torch.Tensor, torch.Tensor]:\n",
        "        optimizer.zero_grad()\n",
        "        out = self.forward(x[:, :-1])\n",
        "        ce = nn.CrossEntropyLoss()\n",
        "        loss = ce(out.transpose(1,2), x[:, 1:])\n",
        "        if accelerator is not None:\n",
        "            accelerator.backward(loss)\n",
        "        else:\n",
        "            loss.backward()\n",
        "        \n",
        "        # Check for nan gradients and zero them out\n",
        "        for param in self.parameters():\n",
        "            if param.grad is not None and (torch.isnan(param.grad).any() or torch.isinf(param.grad).any()):\n",
        "                param.grad.zero_()\n",
        "                print(f\"Gradient for {param.name} with {param.numel()} elements is {\"nan\" if torch.isnan(param.grad).any() else \"inf\"}. Zeroing out.\")\n",
        "\n",
        "        torch.nn.utils.clip_grad_norm_(self.parameters(), max_norm=1.0)  # clip the gradients\n",
        "        optimizer.step()\n",
        "        scheduler.step()\n",
        "        return loss\n",
        "    \n",
        "    def device(self):\n",
        "        return next(self.parameters()).device\n",
        "\n",
        "    def my_train(self, ds, optimizer, scheduler, epochs=3, accelerator=None):\n",
        "        for _ in tqdm(range(epochs), desc=\"Epochs\"):\n",
        "            for batch in tqdm(ds, desc=\"Batches\"):\n",
        "                \n",
        "                loss = self.train_step(torch.stack(batch, dim=-1).to(self.device()), optimizer, scheduler, accelerator)\n",
        "                print(f\"Loss: {loss.item():0.4f}\")\n",
        "            print(f\"Epoch {_} complete\")\n",
        "            tokens = tokenizer.encode(\"hello there, happy world!\")\n",
        "            tokens = torch.tensor(tokens).unsqueeze(0).to('cuda')\n",
        "            tokens = torch.cat([torch.zeros(1, 5, device='cuda', dtype=tokens.dtype), tokens], dim=1)\n",
        "            generation = self.forward(tokens)\n",
        "            print(tokenizer.decode(generation[0].argmax(dim=-1).tolist()))\n",
        "\n",
        "    def generate(self, x: Int[Tensor, \"batch position\"], new_tokens: int) -> Tuple[torch.Tensor, torch.Tensor]:\n",
        "        returned = x\n",
        "        out = self.forward(x, keep_hidden=True)\n",
        "        next_token = out[:, -1].argmax(dim=-1)\n",
        "        returned = torch.cat([returned, next_token], dim=1)\n",
        "\n",
        "        for _ in range(new_tokens-1):\n",
        "            out = self.forward(next_token, keep_hidden=True, use_hidden=True)\n",
        "            next_token = out[:, -1].argmax(dim=-1)\n",
        "            returned = torch.cat([returned, next_token], dim=1)\n",
        "        return returned\n",
        "\n",
        "    def generate_text(self, text, new_tokens):\n",
        "        tokens = tokenizer.encode(text)\n",
        "        tokens = torch.tensor(tokens).unsqueeze(0).to('cuda')\n",
        "        return tokenizer.decode(self.generate(tokens, new_tokens)[0])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3096185a",
      "metadata": {
        "id": "3096185a"
      },
      "source": [
        "# Get Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "13a6fe8d",
      "metadata": {
        "id": "13a6fe8d"
      },
      "outputs": [],
      "source": [
        "import wget\n",
        "import os\n",
        "if not os.path.exists(\"input.txt\"):\n",
        "    wget.download(\"https://raw.githubusercontent.com/karpathy/char-rnn/master/data/tinyshakespeare/input.txt\")\n",
        "\n",
        "with open('input.txt', 'r') as f:\n",
        "    raw_text = f.read()\n",
        "all_dialogues = raw_text.split('\\n\\n')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "bc7c6703",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "transformers.models.bert.tokenization_bert_fast.BertTokenizerFast"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "type(tokenizer)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "48b54dde",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "list"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "type(all_dialogues)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ccb804ff",
      "metadata": {
        "id": "ccb804ff"
      },
      "source": [
        "## Part 4.A"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "2bb30140",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[101, 7592, 2045, 1010, 3407, 2088, 999, 102]"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "tokenizer.encode(\"hello there, happy world!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "0fcfcf84",
      "metadata": {},
      "outputs": [],
      "source": [
        "def num_params(model):\n",
        "    return sum(p.numel() for p in list(model.parameters()))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "28009334",
      "metadata": {},
      "outputs": [],
      "source": [
        "torch.set_float32_matmul_precision('high')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "id": "793c204b",
      "metadata": {},
      "outputs": [],
      "source": [
        "from datasets import load_dataset\n",
        "\n",
        "# Login using e.g. `huggingface-cli login` to access this dataset\n",
        "ds = load_dataset(\"nampdn-ai/tiny-textbooks\", cache_dir=\"/shared/alex-zhao-storage/hf-cache\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "id": "5fe66396",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of texts: 399000\n",
            "Mean length: 3038.2\n",
            "Std length: 904.0\n",
            "Min length: 102\n",
            "Max length: 34104\n",
            "Median length: 2938.0\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "lengths = [len(text) for text in ds['train']['textbook']]\n",
        "print(f\"Number of texts: {len(lengths)}\")\n",
        "print(f\"Mean length: {np.mean(lengths):.1f}\")\n",
        "print(f\"Std length: {np.std(lengths):.1f}\") \n",
        "print(f\"Min length: {min(lengths)}\")\n",
        "print(f\"Max length: {max(lengths)}\")\n",
        "print(f\"Median length: {np.median(lengths):.1f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c55411da",
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "id": "9e999cc1",
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipykernel_1199169/1988863541.py:1: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  L = torch.load('/shared/alex-zhao-storage/tiny-textbook-ds.pt')\n"
          ]
        }
      ],
      "source": [
        "L = torch.load('/shared/alex-zhao-storage/tiny-textbook-ds.pt')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "id": "1ac8775a",
      "metadata": {},
      "outputs": [],
      "source": [
        "dataloader = DataLoader(L['input_ids'], batch_size=16)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "id": "96cc2b26",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "15551106\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "48f54a600dee4925a1afe2eff3ba26b8",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Epochs:   0%|          | 0/3 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "5b5268f4b66e478abe6f73fcda74dc65",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Batches:   0%|          | 0/24938 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loss: 12.2798\n",
            "Loss: 11.3717\n",
            "Loss: 11.1144\n",
            "Loss: 10.6179\n",
            "Loss: 10.3236\n",
            "Loss: 10.2746\n",
            "Loss: 10.0716\n",
            "Loss: 9.4894\n",
            "Loss: 8.8021\n",
            "Loss: 8.8037\n",
            "Loss: 8.5014\n",
            "Loss: 8.3728\n",
            "Loss: 8.1191\n",
            "Loss: 7.7341\n",
            "Loss: 7.3607\n",
            "Loss: 7.5355\n",
            "Loss: 7.0096\n",
            "Loss: 6.9645\n",
            "Loss: 6.7231\n",
            "Loss: 7.1180\n",
            "Loss: 6.7047\n",
            "Loss: 6.6254\n",
            "Loss: 6.8813\n",
            "Loss: 7.0882\n",
            "Loss: 6.6897\n",
            "Loss: 5.9256\n",
            "Loss: 6.8095\n",
            "Loss: 6.6116\n",
            "Loss: 6.2940\n",
            "Loss: 6.3381\n",
            "Loss: 6.5457\n",
            "Loss: 6.7038\n",
            "Loss: 5.8006\n",
            "Loss: 6.0059\n",
            "Loss: 6.5033\n",
            "Loss: 5.9802\n",
            "Loss: 6.1814\n",
            "Loss: 5.8401\n",
            "Loss: 6.5157\n",
            "Loss: 6.3547\n",
            "Loss: 6.1754\n",
            "Loss: 6.4958\n",
            "Loss: 6.1868\n",
            "Loss: 5.9678\n",
            "Loss: 6.4697\n",
            "Loss: 6.2115\n",
            "Loss: 6.3543\n",
            "Loss: 6.1638\n",
            "Loss: 6.2699\n",
            "Loss: 6.2952\n",
            "Loss: 6.1564\n",
            "Loss: 5.8639\n",
            "Loss: 6.2584\n",
            "Loss: 6.1265\n",
            "Loss: 5.8160\n",
            "Loss: 6.0720\n",
            "Loss: 5.8823\n",
            "Loss: 5.5612\n",
            "Loss: 5.9140\n",
            "Loss: 5.8666\n",
            "Loss: 5.9171\n",
            "Loss: 6.0846\n",
            "Loss: 6.2215\n",
            "Loss: 5.8964\n",
            "Loss: 6.0801\n",
            "Loss: 5.3826\n",
            "Loss: 5.6099\n",
            "Loss: 5.8773\n",
            "Loss: 5.7546\n",
            "Loss: 5.8774\n",
            "Loss: 5.9821\n",
            "Loss: 5.7672\n",
            "Loss: 5.6824\n",
            "Loss: 5.6956\n",
            "Loss: 6.0511\n",
            "Loss: 6.2102\n",
            "Loss: 5.6439\n",
            "Loss: 6.0702\n",
            "Loss: 5.9682\n",
            "Loss: 5.6056\n",
            "Loss: 6.2527\n",
            "Loss: 5.7221\n",
            "Loss: 5.5504\n",
            "Loss: 6.1009\n",
            "Loss: 5.4120\n",
            "Loss: 5.4803\n",
            "Loss: 5.8773\n",
            "Loss: 5.6784\n",
            "Loss: 6.1784\n",
            "Loss: 5.6601\n",
            "Loss: 5.8379\n",
            "Loss: 5.7102\n",
            "Loss: 6.0549\n",
            "Loss: 5.6098\n",
            "Loss: 5.8746\n",
            "Loss: 6.0683\n",
            "Loss: 5.9774\n",
            "Loss: 6.0172\n",
            "Loss: 5.5907\n",
            "Loss: 5.7952\n",
            "Loss: 5.8647\n",
            "Loss: 5.9228\n",
            "Loss: 6.0299\n",
            "Loss: 5.8995\n",
            "Loss: 5.6852\n",
            "Loss: 5.4866\n",
            "Loss: 5.5490\n",
            "Loss: 5.9222\n",
            "Loss: 5.6061\n",
            "Loss: 5.8544\n",
            "Loss: 5.9902\n",
            "Loss: 5.8259\n",
            "Loss: 6.0246\n",
            "Loss: 6.0636\n",
            "Loss: 5.8241\n",
            "Loss: 6.0485\n",
            "Loss: 5.8160\n",
            "Loss: 5.6450\n",
            "Loss: 5.9339\n",
            "Loss: 5.7796\n",
            "Loss: 5.4584\n",
            "Loss: 5.6085\n",
            "Loss: 5.8490\n",
            "Loss: 5.6134\n",
            "Loss: 5.9259\n",
            "Loss: 5.8514\n",
            "Loss: 5.9421\n",
            "Loss: 6.0215\n",
            "Loss: 6.0025\n",
            "Loss: 6.0986\n",
            "Loss: 5.7616\n",
            "Loss: 6.0315\n",
            "Loss: 5.6971\n",
            "Loss: 5.6403\n",
            "Loss: 5.5041\n",
            "Loss: 5.6475\n",
            "Loss: 5.8051\n",
            "Loss: 5.8716\n",
            "Loss: 5.7397\n",
            "Loss: 5.7829\n",
            "Loss: 5.7349\n",
            "Loss: 5.2755\n",
            "Loss: 5.9321\n",
            "Loss: 5.4266\n",
            "Loss: 5.9796\n",
            "Loss: 5.7309\n",
            "Loss: 5.5224\n",
            "Loss: 5.4483\n",
            "Loss: 6.0400\n",
            "Loss: 6.0869\n",
            "Loss: 6.0131\n",
            "Loss: 5.9874\n",
            "Loss: 5.6635\n",
            "Loss: 5.8037\n",
            "Loss: 5.4421\n",
            "Loss: 5.7048\n",
            "Loss: 5.4718\n",
            "Loss: 5.1150\n",
            "Loss: 5.6166\n"
          ]
        }
      ],
      "source": [
        "model = MambaLM(tokenizer.vocab_size, \n",
        "                n_layers=12,\n",
        "                n_heads=6,\n",
        "                d_model=192,\n",
        "                d_state=32,\n",
        "                d_conv=4,\n",
        "                expand=2,\n",
        "                ).to('cuda')\n",
        "print(num_params(model))\n",
        "optimizer = torch.optim.AdamW(model.parameters(), betas=(0.9, 0.95), weight_decay=0.1, lr=0.001)\n",
        "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=100)\n",
        "model = torch.compile(model)\n",
        "# L = tokenizer.batch_encode_plus(ds['train']['textbook'], padding=True, truncation=True, max_length=513, padding_side='left', return_tensors='pt').to('cuda')\n",
        "# torch.save(L, '/shared/alex-zhao-storage/tiny-textbook-ds.pt')\n",
        "# dataloader = DataLoader(L['input_ids'], batch_size=32)\n",
        "# L = tokenizer.batch_encode_plus(all_dialogues, padding=True, truncation=True, max_length=65, padding_side='left').to('cuda')\n",
        "# dataloader = DataLoader(L['input_ids'], batch_size=4)\n",
        "model.my_train(dataloader, optimizer, scheduler)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "id": "58f24465",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "> \u001b[0;32m/tmp/ipykernel_1186111/1262274794.py\u001b[0m(32)\u001b[0;36mforward\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m     30 \u001b[0;31m        \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mpos_embed\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0m\u001b[0;32m     31 \u001b[0;31m        \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misnan\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0many\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misinf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0many\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0m\u001b[0;32m---> 32 \u001b[0;31m            \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"NaN or Inf values detected in MambaLM input\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0m\u001b[0;32m     33 \u001b[0;31m        \u001b[0;32mfor\u001b[0m \u001b[0mlayer\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0m\u001b[0;32m     34 \u001b[0;31m            \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0m\n",
            "tensor([[[ 0.0000e+00,  1.0000e+00,  0.0000e+00,  ...,  1.0000e+00,\n",
            "           0.0000e+00,  1.0000e+00],\n",
            "         [ 0.0000e+00,  1.0000e+00,  0.0000e+00,  ...,  1.0000e+00,\n",
            "           0.0000e+00,  1.0000e+00],\n",
            "         [ 0.0000e+00,  1.0000e+00,  0.0000e+00,  ...,  1.0000e+00,\n",
            "           0.0000e+00,  1.0000e+00],\n",
            "         ...,\n",
            "         [-6.5026e-01,  6.8840e-01, -1.0753e-03,  ...,  9.9909e-01,\n",
            "           4.0714e-02,  9.9925e-01],\n",
            "         [ 2.8793e-01, -1.9266e-01, -7.8927e-01,  ...,  9.9908e-01,\n",
            "           4.0824e-02,  9.9924e-01],\n",
            "         [ 9.6141e-01, -9.1155e-01, -9.6957e-01,  ...,  9.9908e-01,\n",
            "           4.0934e-02,  9.9924e-01]],\n",
            "\n",
            "        [[ 0.0000e+00,  1.0000e+00,  0.0000e+00,  ...,  1.0000e+00,\n",
            "           0.0000e+00,  1.0000e+00],\n",
            "         [ 0.0000e+00,  1.0000e+00,  0.0000e+00,  ...,  1.0000e+00,\n",
            "           0.0000e+00,  1.0000e+00],\n",
            "         [ 0.0000e+00,  1.0000e+00,  0.0000e+00,  ...,  1.0000e+00,\n",
            "           0.0000e+00,  1.0000e+00],\n",
            "         ...,\n",
            "         [-8.2681e-01, -2.2319e-01, -9.9206e-01,  ...,  9.9882e-01,\n",
            "           4.6213e-02,  9.9903e-01],\n",
            "         [ 2.6581e-02,  6.6545e-01, -7.0923e-01,  ...,  9.9882e-01,\n",
            "           4.6323e-02,  9.9902e-01],\n",
            "         [ 8.5554e-01,  9.9391e-01,  1.1982e-01,  ...,  9.9881e-01,\n",
            "           4.6433e-02,  9.9902e-01]],\n",
            "\n",
            "        [[ 0.0000e+00,  1.0000e+00,  0.0000e+00,  ...,  1.0000e+00,\n",
            "           0.0000e+00,  1.0000e+00],\n",
            "         [ 8.4147e-01,  5.7911e-01,  7.8859e-01,  ...,  1.0000e+00,\n",
            "           1.1007e-04,  1.0000e+00],\n",
            "         [ 9.0930e-01, -3.2927e-01,  9.6984e-01,  ...,  1.0000e+00,\n",
            "           2.2014e-04,  1.0000e+00],\n",
            "         ...,\n",
            "         [ 6.1950e-02,  2.1498e-01, -5.8212e-01,  ...,  9.9827e-01,\n",
            "           5.5996e-02,  9.9857e-01],\n",
            "         [ 8.7333e-01, -6.7169e-01, -9.9916e-01,  ...,  9.9827e-01,\n",
            "           5.6106e-02,  9.9857e-01],\n",
            "         [ 8.8177e-01, -9.9295e-01, -6.4669e-01,  ...,  9.9826e-01,\n",
            "           5.6216e-02,  9.9856e-01]],\n",
            "\n",
            "        ...,\n",
            "\n",
            "        [[ 0.0000e+00,  1.0000e+00,  0.0000e+00,  ...,  1.0000e+00,\n",
            "           0.0000e+00,  1.0000e+00],\n",
            "         [ 8.4147e-01,  5.7911e-01,  7.8859e-01,  ...,  1.0000e+00,\n",
            "           1.1007e-04,  1.0000e+00],\n",
            "         [ 9.0930e-01, -3.2927e-01,  9.6984e-01,  ...,  1.0000e+00,\n",
            "           2.2014e-04,  1.0000e+00],\n",
            "         ...,\n",
            "         [ 6.1950e-02,  2.1498e-01, -5.8212e-01,  ...,  9.9827e-01,\n",
            "           5.5996e-02,  9.9857e-01],\n",
            "         [ 8.7333e-01, -6.7169e-01, -9.9916e-01,  ...,  9.9827e-01,\n",
            "           5.6106e-02,  9.9857e-01],\n",
            "         [ 8.8177e-01, -9.9295e-01, -6.4669e-01,  ...,  9.9826e-01,\n",
            "           5.6216e-02,  9.9856e-01]],\n",
            "\n",
            "        [[ 0.0000e+00,  1.0000e+00,  0.0000e+00,  ...,  1.0000e+00,\n",
            "           0.0000e+00,  1.0000e+00],\n",
            "         [ 8.4147e-01,  5.7911e-01,  7.8859e-01,  ...,  1.0000e+00,\n",
            "           1.1007e-04,  1.0000e+00],\n",
            "         [ 9.0930e-01, -3.2927e-01,  9.6984e-01,  ...,  1.0000e+00,\n",
            "           2.2014e-04,  1.0000e+00],\n",
            "         ...,\n",
            "         [ 6.1950e-02,  2.1498e-01, -5.8212e-01,  ...,  9.9827e-01,\n",
            "           5.5996e-02,  9.9857e-01],\n",
            "         [ 8.7333e-01, -6.7169e-01, -9.9916e-01,  ...,  9.9827e-01,\n",
            "           5.6106e-02,  9.9857e-01],\n",
            "         [ 8.8177e-01, -9.9295e-01, -6.4669e-01,  ...,  9.9826e-01,\n",
            "           5.6216e-02,  9.9856e-01]],\n",
            "\n",
            "        [[ 0.0000e+00,  1.0000e+00,  0.0000e+00,  ...,  1.0000e+00,\n",
            "           0.0000e+00,  1.0000e+00],\n",
            "         [ 8.4147e-01,  5.7911e-01,  7.8859e-01,  ...,  1.0000e+00,\n",
            "           1.1007e-04,  1.0000e+00],\n",
            "         [ 9.0930e-01, -3.2927e-01,  9.6984e-01,  ...,  1.0000e+00,\n",
            "           2.2014e-04,  1.0000e+00],\n",
            "         ...,\n",
            "         [ 6.1950e-02,  2.1498e-01, -5.8212e-01,  ...,  9.9827e-01,\n",
            "           5.5996e-02,  9.9857e-01],\n",
            "         [ 8.7333e-01, -6.7169e-01, -9.9916e-01,  ...,  9.9827e-01,\n",
            "           5.6106e-02,  9.9857e-01],\n",
            "         [ 8.8177e-01, -9.9295e-01, -6.4669e-01,  ...,  9.9826e-01,\n",
            "           5.6216e-02,  9.9856e-01]]], device='cuda:0')\n",
            "0\n",
            "tensor(False, device='cuda:0')\n",
            "tensor(True, device='cuda:0')\n",
            "tensor(True, device='cuda:0')\n",
            "tensor([[[nan, nan, nan,  ..., nan, nan, nan],\n",
            "         [nan, nan, nan,  ..., nan, nan, nan],\n",
            "         [nan, nan, nan,  ..., nan, nan, nan],\n",
            "         ...,\n",
            "         [nan, nan, nan,  ..., nan, nan, nan],\n",
            "         [nan, nan, nan,  ..., nan, nan, nan],\n",
            "         [nan, nan, nan,  ..., nan, nan, nan]],\n",
            "\n",
            "        [[nan, nan, nan,  ..., nan, nan, nan],\n",
            "         [nan, nan, nan,  ..., nan, nan, nan],\n",
            "         [nan, nan, nan,  ..., nan, nan, nan],\n",
            "         ...,\n",
            "         [nan, nan, nan,  ..., nan, nan, nan],\n",
            "         [nan, nan, nan,  ..., nan, nan, nan],\n",
            "         [nan, nan, nan,  ..., nan, nan, nan]],\n",
            "\n",
            "        [[nan, nan, nan,  ..., nan, nan, nan],\n",
            "         [nan, nan, nan,  ..., nan, nan, nan],\n",
            "         [nan, nan, nan,  ..., nan, nan, nan],\n",
            "         ...,\n",
            "         [nan, nan, nan,  ..., nan, nan, nan],\n",
            "         [nan, nan, nan,  ..., nan, nan, nan],\n",
            "         [nan, nan, nan,  ..., nan, nan, nan]],\n",
            "\n",
            "        ...,\n",
            "\n",
            "        [[nan, nan, nan,  ..., nan, nan, nan],\n",
            "         [nan, nan, nan,  ..., nan, nan, nan],\n",
            "         [nan, nan, nan,  ..., nan, nan, nan],\n",
            "         ...,\n",
            "         [nan, nan, nan,  ..., nan, nan, nan],\n",
            "         [nan, nan, nan,  ..., nan, nan, nan],\n",
            "         [nan, nan, nan,  ..., nan, nan, nan]],\n",
            "\n",
            "        [[nan, nan, nan,  ..., nan, nan, nan],\n",
            "         [nan, nan, nan,  ..., nan, nan, nan],\n",
            "         [nan, nan, nan,  ..., nan, nan, nan],\n",
            "         ...,\n",
            "         [nan, nan, nan,  ..., nan, nan, nan],\n",
            "         [nan, nan, nan,  ..., nan, nan, nan],\n",
            "         [nan, nan, nan,  ..., nan, nan, nan]],\n",
            "\n",
            "        [[nan, nan, nan,  ..., nan, nan, nan],\n",
            "         [nan, nan, nan,  ..., nan, nan, nan],\n",
            "         [nan, nan, nan,  ..., nan, nan, nan],\n",
            "         ...,\n",
            "         [nan, nan, nan,  ..., nan, nan, nan],\n",
            "         [nan, nan, nan,  ..., nan, nan, nan],\n",
            "         [nan, nan, nan,  ..., nan, nan, nan]]], device='cuda:0',\n",
            "       grad_fn=<AddBackward0>)\n",
            "tensor([[[nan, nan, nan,  ..., nan, nan, nan],\n",
            "         [nan, nan, nan,  ..., nan, nan, nan],\n",
            "         [nan, nan, nan,  ..., nan, nan, nan],\n",
            "         ...,\n",
            "         [nan, nan, nan,  ..., nan, nan, nan],\n",
            "         [nan, nan, nan,  ..., nan, nan, nan],\n",
            "         [nan, nan, nan,  ..., nan, nan, nan]],\n",
            "\n",
            "        [[nan, nan, nan,  ..., nan, nan, nan],\n",
            "         [nan, nan, nan,  ..., nan, nan, nan],\n",
            "         [nan, nan, nan,  ..., nan, nan, nan],\n",
            "         ...,\n",
            "         [nan, nan, nan,  ..., nan, nan, nan],\n",
            "         [nan, nan, nan,  ..., nan, nan, nan],\n",
            "         [nan, nan, nan,  ..., nan, nan, nan]],\n",
            "\n",
            "        [[nan, nan, nan,  ..., nan, nan, nan],\n",
            "         [nan, nan, nan,  ..., nan, nan, nan],\n",
            "         [nan, nan, nan,  ..., nan, nan, nan],\n",
            "         ...,\n",
            "         [nan, nan, nan,  ..., nan, nan, nan],\n",
            "         [nan, nan, nan,  ..., nan, nan, nan],\n",
            "         [nan, nan, nan,  ..., nan, nan, nan]],\n",
            "\n",
            "        ...,\n",
            "\n",
            "        [[nan, nan, nan,  ..., nan, nan, nan],\n",
            "         [nan, nan, nan,  ..., nan, nan, nan],\n",
            "         [nan, nan, nan,  ..., nan, nan, nan],\n",
            "         ...,\n",
            "         [nan, nan, nan,  ..., nan, nan, nan],\n",
            "         [nan, nan, nan,  ..., nan, nan, nan],\n",
            "         [nan, nan, nan,  ..., nan, nan, nan]],\n",
            "\n",
            "        [[nan, nan, nan,  ..., nan, nan, nan],\n",
            "         [nan, nan, nan,  ..., nan, nan, nan],\n",
            "         [nan, nan, nan,  ..., nan, nan, nan],\n",
            "         ...,\n",
            "         [nan, nan, nan,  ..., nan, nan, nan],\n",
            "         [nan, nan, nan,  ..., nan, nan, nan],\n",
            "         [nan, nan, nan,  ..., nan, nan, nan]],\n",
            "\n",
            "        [[nan, nan, nan,  ..., nan, nan, nan],\n",
            "         [nan, nan, nan,  ..., nan, nan, nan],\n",
            "         [nan, nan, nan,  ..., nan, nan, nan],\n",
            "         ...,\n",
            "         [nan, nan, nan,  ..., nan, nan, nan],\n",
            "         [nan, nan, nan,  ..., nan, nan, nan],\n",
            "         [nan, nan, nan,  ..., nan, nan, nan]]], device='cuda:0',\n",
            "       grad_fn=<AddBackward0>)\n"
          ]
        }
      ],
      "source": [
        "%debug"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "id": "bc7acd2c",
      "metadata": {},
      "outputs": [],
      "source": [
        "del model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "id": "3b76c3c3",
      "metadata": {},
      "outputs": [],
      "source": [
        "import gc\n",
        "import torch\n",
        "\n",
        "# Clear GPU memory\n",
        "gc.collect()\n",
        "torch.cuda.empty_cache()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "id": "8d5a0e58",
      "metadata": {},
      "outputs": [],
      "source": [
        "# ds = load_dataset(\"nampdn-ai/tiny-textbooks\", cache_dir=\"/shared/alex-zhao-storage/hf-cache\")\n",
        "# L = tokenizer.batch_encode_plus(ds['train']['textbook'], padding=True, truncation=True, max_length=513, padding_side='left')\n",
        "# dataloader = DataLoader(L['input_ids'], batch_size=8)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "id": "cd3f86cd",
      "metadata": {},
      "outputs": [],
      "source": [
        "def special_print(my_str, accelerator):\n",
        "    if accelerator.is_main_process:\n",
        "        print(my_str)\n",
        "        print_time()\n",
        "\n",
        "def print_time():\n",
        "    from datetime import datetime\n",
        "    now = datetime.now()\n",
        "    current_time = now.strftime(\"%H:%M:%S.%f\")[:-3]\n",
        "    print(\"Current Time =\", current_time)\n",
        "\n",
        "vocab_size = tokenizer.vocab_size\n",
        "\n",
        "def training_function():\n",
        "    accelerator = Accelerator()\n",
        "    \n",
        "    model = MambaLM(vocab_size, \n",
        "                n_layers=12,\n",
        "                n_heads=6,\n",
        "                d_model=192,\n",
        "                d_state=32,\n",
        "                d_conv=4,\n",
        "                expand=2,\n",
        "                )\n",
        "    \n",
        "    special_print(f\"Model params: {num_params(model)}\", accelerator)\n",
        "\n",
        "    # 4. Prepare with Accelerator\n",
        "    # L = tokenizer.batch_encode_plus(all_dialogues, padding=True, truncation=True, max_length=65, padding_side='left').to('cuda')\n",
        "    # dataloader = DataLoader(L['input_ids'], batch_size=4)\n",
        "\n",
        "    # optimizer = torch.optim.AdamW(model.parameters(), lr=0.0001)\n",
        "    # scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=100)\n",
        "\n",
        "    model, dataloader, optimizer, scheduler = accelerator.prepare(model, dataloader, optimizer, scheduler)\n",
        "    special_print(\"Prepared with Accelerator\", accelerator)\n",
        "    model = torch.compile(model)\n",
        "    special_print(\"Model compiled\", accelerator)\n",
        "\n",
        "    epochs = 1\n",
        "    progress_bar = None\n",
        "    if accelerator.is_main_process:\n",
        "        progress_bar = tqdm(total=epochs * len(dataloader), desc=\"Training Progress\")\n",
        "        \n",
        "    MambaLM.my_train(model, dataloader, optimizer, scheduler, epochs, accelerator)\n",
        "    \n",
        "    if accelerator.is_main_process:\n",
        "        progress_bar.close()\n",
        "\n",
        "    # 6. Save final model\n",
        "    # Must unwrap to gather full weights from all shards\n",
        "    unwrapped_model = accelerator.unwrap_model(model)\n",
        "    torch.save(unwrapped_model.state_dict(), \"my_fsdp_fp32_model.pt\")\n",
        "    print(\"Model saved at my_fsdp_fp32_model.pt\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "id": "6fa7b069",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Launching training on 8 GPUs.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model params: 15551106\n",
            "Current Time = 02:00:31.677\n",
            "Prepared with Accelerator\n",
            "Current Time = 02:00:47.029\n",
            "cudaModel compiled\n",
            "\n",
            "Current Time = 02:00:48.171\n",
            "cuda\n",
            "cuda\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "574525634f894549933e100e66364d94",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Training Progress:   0%|          | 0/226 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "cuda\n",
            "cuda\n",
            "Starting batch 0cuda\n",
            "\n",
            "cudacudaCurrent Time = \n",
            "\n",
            "02:00:48.202\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[rank2]:W1224 02:00:48.220000 1160851 torch/_logging/_internal.py:1081] [0/0] Profiler function <class 'torch.autograd.profiler.record_function'> will be ignored\n",
            "[rank1]:W1224 02:00:48.222000 1160849 torch/_logging/_internal.py:1081] [0/0] Profiler function <class 'torch.autograd.profiler.record_function'> will be ignored\n",
            "[rank4]:W1224 02:00:48.223000 1160855 torch/_logging/_internal.py:1081] [0/0] Profiler function <class 'torch.autograd.profiler.record_function'> will be ignored\n",
            "[rank3]:W1224 02:00:48.234000 1160853 torch/_logging/_internal.py:1081] [0/0] Profiler function <class 'torch.autograd.profiler.record_function'> will be ignored\n",
            "[rank5]:W1224 02:00:48.236000 1160857 torch/_logging/_internal.py:1081] [0/0] Profiler function <class 'torch.autograd.profiler.record_function'> will be ignored\n",
            "[rank0]:W1224 02:00:48.243000 1160847 torch/_logging/_internal.py:1081] [0/0] Profiler function <class 'torch.autograd.profiler.record_function'> will be ignored\n",
            "[rank6]:W1224 02:00:48.244000 1160859 torch/_logging/_internal.py:1081] [0/0] Profiler function <class 'torch.autograd.profiler.record_function'> will be ignored\n",
            "[rank7]:W1224 02:00:48.249000 1160861 torch/_logging/_internal.py:1081] [0/0] Profiler function <class 'torch.autograd.profiler.record_function'> will be ignored\n",
            "Fatal Python error: Fatal Python error: Segmentation fault\n",
            "\n",
            "Thread 0x00001517e11e8640 (most recent call first):\n",
            "  <no Python frame>\n",
            "\n",
            "Thread 0x00001517e0fe7640 (most recent call first):\n",
            "  <no Python frame>\n",
            "Segmentation fault\n",
            "\n",
            "\n",
            "Thread 0xThread 0x00001517e0de6640 (most recent call first):\n",
            "  <no Python frame>\n",
            "\n",
            "Thread 0x00001517e0be5640 (most recent call first):\n",
            "  <no Python frame>\n",
            "\n",
            "Thread 0x00001517e09e4640 (most recent call first):\n",
            "  <no Python frame>\n",
            "\n",
            "Thread 0x00001517e0de6640 (most recent call first):\n",
            "00001517e07e3640 (most recent call first):\n",
            "  <no Python frame>\n",
            "  <no Python frame>\n",
            "\n",
            "\n",
            "Thread 0xThread 0x00001517e05e2640 (most recent call first):\n",
            "  <no Python frame>\n",
            "\n",
            "Thread 0x00001517e11e864000001517e03e1640 (most recent call first):\n",
            " (most recent call first):\n",
            "  <no Python frame>\n",
            "  <no Python frame>\n",
            "\n",
            "\n",
            "Thread 0xThread 0x00001517dbfff640 (most recent call first):\n",
            "  File 00001517e0fe7640\" (most recent call first):\n",
            "/usr/lib/python3.10/threading.py  <no Python frame>\n",
            "\"\n",
            "Thread 0x, line 324 in wait\n",
            "00001517e05e2640  File  (most recent call first):\n",
            "\"  <no Python frame>\n",
            "\n",
            "/usr/lib/python3.10/threading.pyThread 0x\", line 607 in wait\n",
            "  File 00001517e0be5640 (most recent call first):\n",
            "\"  <no Python frame>\n",
            "/home/alex-zhao/.venv/lib/python3.10/site-packages/tqdm/_monitor.py\n",
            "\"Thread 0x, line 60 in run\n",
            "  File \"00001517e09e4640/usr/lib/python3.10/threading.py (most recent call first):\n",
            "\"  <no Python frame>\n",
            "\n",
            ", line Thread 0x1016 in _bootstrap_inner\n",
            "  File \"/usr/lib/python3.10/threading.py\"00001517e07e3640 (most recent call first):\n",
            ", line   <no Python frame>\n",
            "973\n",
            " in Thread 0x_bootstrap\n",
            "\n",
            "Thread 0x00001517da7f3640 (most recent call first):\n",
            "00001517e03e1640  File  (most recent call first):\n",
            "  <no Python frame>\n",
            "\"\n",
            "Thread 0x/home/alex-zhao/.venv/lib/python3.10/site-packages/torch/_inductor/compile_worker/subproc_pool.py\"00001517dbfff640 (most recent call first):\n",
            ", line 47 in _recv_msg\n",
            "  File \"/home/alex-zhao/.venv/lib/python3.10/site-packages/torch/_inductor/compile_worker/subproc_pool.py\"  File , line 153\" in /usr/lib/python3.10/threading.py_read_thread\"\n",
            ", line 324 in   File \"wait/usr/lib/python3.10/threading.py\n",
            "\", line 953 in run\n",
            "  File   File \"/usr/lib/python3.10/threading.py\"\"/home/alex-zhao/.venv/lib/python3.10/site-packages/ipykernel/ipkernel.py\", line 607, line  in 766wait in \n",
            "run_closure\n",
            "  File   File \"/usr/lib/python3.10/threading.py\", line 1016 in _bootstrap_inner\n",
            "\"  File /home/alex-zhao/.venv/lib/python3.10/site-packages/tqdm/_monitor.py\"\"/usr/lib/python3.10/threading.py\", line 60, line  in 973run in \n",
            "_bootstrap\n",
            "\n",
            "  File Current thread 0x\"0000151996ed21c0/usr/lib/python3.10/threading.py (most recent call first):\n",
            "\"  File , line \"1016/tmp/ipykernel_1160500/4248888456.py in \", line 19 in _bootstrap_innertorch_dynamo_resume_in_forward_at_16\n",
            "\n",
            "  File \"  File /tmp/ipykernel_1160500/4248888456.py\"\"/usr/lib/python3.10/threading.py\", line 14 in torch_dynamo_resume_in_forward_at_14, line \n",
            "973 in   File _bootstrap\"\n",
            "/tmp/ipykernel_1160500/4248888456.py\n",
            "\"Thread 0x, line 1300001517da7f3640 in  (most recent call first):\n",
            "forward\n",
            "  File \"/home/alex-zhao/.venv/lib/python3.10/site-packages/torch/_inductor/compile_worker/subproc_pool.py  File \"\", line /home/alex-zhao/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py47\" in , line _recv_msg1747\n",
            " in _call_impl\n",
            "  File   File \"\"/home/alex-zhao/.venv/lib/python3.10/site-packages/torch/_inductor/compile_worker/subproc_pool.py/home/alex-zhao/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py\"\", line , line 1531736 in  in _read_thread_wrapped_call_impl\n",
            "\n",
            "  File \"/tmp/ipykernel_1160500/161130724.py  File \"\", line /usr/lib/python3.10/threading.py26\" in , line torch_dynamo_resume_in_forward_at_20953\n",
            " in run\n",
            "  File \"/tmp/ipykernel_1160500/161130724.py  File \"\", line 20/home/alex-zhao/.venv/lib/python3.10/site-packages/ipykernel/ipkernel.py in \"torch_dynamo_resume_in_forward_at_20, line \n",
            "766 in   File run_closure\"\n",
            "/tmp/ipykernel_1160500/161130724.py\", line 12  File  in \"forward/usr/lib/python3.10/threading.py\n",
            "\", line   File 1016\" in /home/alex-zhao/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py_bootstrap_inner\"\n",
            ", line 1747 in _call_impl\n",
            "  File \"  File /usr/lib/python3.10/threading.py\"\"/home/alex-zhao/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py, line \"973, line  in 1736_bootstrap in \n",
            "_wrapped_call_impl\n",
            "\n",
            "Fatal Python error: Current thread 0x  File Segmentation fault0000151996ed21c0\"\n",
            "\n",
            " (most recent call first):\n",
            "/home/alex-zhao/.venv/lib/python3.10/site-packages/torch/nn/parallel/distributed.pyThread 0x  File \"00001517e11e8640\" (most recent call first):\n",
            ", line   <no Python frame>\n",
            "/tmp/ipykernel_1160500/4248888456.py1459\n",
            "\" in Thread 0x, line _run_ddp_forward1900001517e0fe7640\n",
            " in  (most recent call first):\n",
            "  File torch_dynamo_resume_in_forward_at_16  <no Python frame>\n",
            "\n",
            "\"\n",
            "/home/alex-zhao/.venv/lib/python3.10/site-packages/torch/nn/parallel/distributed.pyThread 0x  File \"00001517e0de6640\", line  (most recent call first):\n",
            "/tmp/ipykernel_1160500/4248888456.py1643  <no Python frame>\n",
            "\"\n",
            " in Thread 0x, line 00001517e0be5640forward (most recent call first):\n",
            "14\n",
            "  <no Python frame>\n",
            " in   File \n",
            "torch_dynamo_resume_in_forward_at_14\"\n",
            "Thread 0x/home/alex-zhao/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py  File 00001517e09e4640\" (most recent call first):\n",
            "\"  <no Python frame>\n",
            ", line /tmp/ipykernel_1160500/4248888456.py1747\n",
            "\" in , line Thread 0x13_call_impl in 00001517e07e3640\n",
            " (most recent call first):\n",
            "forward  <no Python frame>\n",
            "  File \n",
            "\n",
            "\"Thread 0x/home/alex-zhao/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py  File \"00001517e05e2640, line \"1736 (most recent call first):\n",
            "/home/alex-zhao/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py  <no Python frame>\n",
            " in \"\n",
            "_wrapped_call_impl, line \n",
            "Thread 0x1747  File 00001517e03e1640 in  (most recent call first):\n",
            "\"_call_impl  <no Python frame>\n",
            "/home/alex-zhao/.venv/lib/python3.10/site-packages/torch/_dynamo/external_utils.py\n",
            "\n",
            "\"Thread 0x  File , line 00001517dbfff64040 (most recent call first):\n",
            "\" in /home/alex-zhao/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py\"inner\n",
            ", line 1736 in   File _wrapped_call_impl\n",
            "\"  File   File /home/alex-zhao/.venv/lib/python3.10/site-packages/torch/_dynamo/eval_frame.py\"\"/usr/lib/python3.10/threading.py\"\", line /tmp/ipykernel_1160500/161130724.py465, line \" in 324, line  in _fn26\n",
            "wait in \n",
            "  File torch_dynamo_resume_in_forward_at_20  File \n",
            "\"\"/tmp/ipykernel_1160500/3913905366.py/usr/lib/python3.10/threading.py  File \"\"\"/tmp/ipykernel_1160500/161130724.py, line \", line 54, line 60720 in  in  in training_functionwaittorch_dynamo_resume_in_forward_at_20\n",
            "\n",
            "\n",
            "  File   File   File \"\"/home/alex-zhao/.venv/lib/python3.10/site-packages/torch/distributed/elastic/multiprocessing/errors/__init__.py/tmp/ipykernel_1160500/161130724.py\"\", line 355, line \" in 12/home/alex-zhao/.venv/lib/python3.10/site-packages/tqdm/_monitor.pywrapper in \"\n",
            "forward, line   File 60\n",
            "\" in   File run/home/alex-zhao/.venv/lib/python3.10/site-packages/torch/distributed/elastic/multiprocessing/api.py\"\n",
            "\"/home/alex-zhao/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py\", line , line   File 6111747 in \"_wrap in /usr/lib/python3.10/threading.py_call_impl\n",
            "\"\n",
            "  File , line   File 1016\"\" in /home/alex-zhao/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py/home/alex-zhao/.venv/lib/python3.10/site-packages/torch/multiprocessing/spawn.py\"_bootstrap_inner, line \n",
            "\"1736, line  in 90_wrapped_call_impl in \n",
            "_wrap  File \n",
            "\"  File /usr/lib/python3.10/threading.py  File \"\"\", line /home/alex-zhao/.venv/lib/python3.10/site-packages/torch/nn/parallel/distributed.py/usr/lib/python3.10/multiprocessing/process.py\"\"973, line , line  in 1081459 in _bootstrap in run\n",
            "_run_ddp_forward\n",
            "\n",
            "\n",
            "Thread 0x  File   File 00001517da7f3640\"\" (most recent call first):\n",
            "/usr/lib/python3.10/multiprocessing/process.py/home/alex-zhao/.venv/lib/python3.10/site-packages/torch/nn/parallel/distributed.py\"\"  File , line , line 314\"1643 in /home/alex-zhao/.venv/lib/python3.10/site-packages/torch/_inductor/compile_worker/subproc_pool.py in \"_bootstrapforward\n",
            ", line \n",
            "47  File   File \" in \"/usr/lib/python3.10/multiprocessing/popen_fork.py_recv_msg/home/alex-zhao/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py\"\"\n",
            ", line , line   File 711747\" in  in /home/alex-zhao/.venv/lib/python3.10/site-packages/torch/_inductor/compile_worker/subproc_pool.py_launch_call_impl\"\n",
            "\n",
            ", line   File   File \"153\"/usr/lib/python3.10/multiprocessing/popen_fork.py in /home/alex-zhao/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py_read_thread\"\"\n",
            ", line , line 191736  File  in \"__init__/usr/lib/python3.10/threading.py\n",
            "\" in   File , line _wrapped_call_impl953\"\n",
            " in /usr/lib/python3.10/multiprocessing/context.py  File run\"\"\n",
            "/home/alex-zhao/.venv/lib/python3.10/site-packages/torch/_dynamo/external_utils.py, line \"  File 281, line  in \"_Popen40\n",
            "/home/alex-zhao/.venv/lib/python3.10/site-packages/ipykernel/ipkernel.py in \"  File inner\", line \n",
            "/usr/lib/python3.10/multiprocessing/process.py766\" in   File , line run_closure121\"\n",
            " in /home/alex-zhao/.venv/lib/python3.10/site-packages/torch/_dynamo/eval_frame.py\"start\n",
            "  File , line   File \"\"465/usr/lib/python3.10/threading.py/home/alex-zhao/.venv/lib/python3.10/site-packages/torch/multiprocessing/spawn.py in \"\", line , line 1016_fn in 263\n",
            "_bootstrap_inner in \n",
            "start_process  File \n",
            "\"  File   File /tmp/ipykernel_1160500/3913905366.py\"\"\"/home/alex-zhao/.venv/lib/python3.10/site-packages/torch/multiprocessing/spawn.py/usr/lib/python3.10/threading.pyFatal Python error: , line \"\"54Segmentation fault, line , line  in \n",
            "\n",
            "training_function268973\n",
            "Thread 0x in   File  in start_processes\"_bootstrap\n",
            "\n",
            "/home/alex-zhao/.venv/lib/python3.10/site-packages/torch/distributed/elastic/multiprocessing/errors/__init__.py\n",
            "  File \"Current thread 0x00001517e11e8640\", line 0000151996ed21c0 (most recent call first):\n",
            "/home/alex-zhao/.venv/lib/python3.10/site-packages/torch/distributed/elastic/multiprocessing/api.py  <no Python frame>\n",
            "355 (most recent call first):\n",
            "\"\n",
            " in   File , line Thread 0xwrapper\"658\n",
            " in /tmp/ipykernel_1160500/4248888456.py00001517e0fe7640_start (most recent call first):\n",
            "\"  File , line \"\n",
            "/home/alex-zhao/.venv/lib/python3.10/site-packages/torch/distributed/elastic/multiprocessing/api.py  <no Python frame>\n",
            "19  File \n",
            "\"Thread 0x/home/alex-zhao/.venv/lib/python3.10/site-packages/torch/distributed/elastic/multiprocessing/api.py\" in \", line torch_dynamo_resume_in_forward_at_1661100001517e0de6640, line \n",
            "485 in  (most recent call first):\n",
            " in   File _wrap  <no Python frame>\n",
            "start\"\n",
            "\n",
            "\n",
            "/tmp/ipykernel_1160500/4248888456.py  File \"\"Thread 0x/home/alex-zhao/.venv/lib/python3.10/site-packages/torch/distributed/elastic/multiprocessing/__init__.py  File \", line \", line 00001517e0be564022914/home/alex-zhao/.venv/lib/python3.10/site-packages/torch/multiprocessing/spawn.py in  (most recent call first):\n",
            " in \"torch_dynamo_resume_in_forward_at_14start_processes  <no Python frame>\n",
            ", line \n",
            "\n",
            "\n",
            "90  File   File Thread 0x in \"\"_wrap/tmp/ipykernel_1160500/4248888456.py/home/alex-zhao/.venv/lib/python3.10/site-packages/torch/distributed/elastic/agent/server/local_elastic_agent.py\n",
            "\"\"00001517e09e4640, line   File , line \" (most recent call first):\n",
            "34313/usr/lib/python3.10/multiprocessing/process.py  <no Python frame>\n",
            " in \n",
            " in \"forward, line \n",
            "Thread 0x_start_workers108  File \n",
            " in \"  File /home/alex-zhao/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py00001517e07e3640\" (most recent call first):\n",
            "run\", line   <no Python frame>\n",
            "1747\n",
            "/home/alex-zhao/.venv/lib/python3.10/site-packages/torch/distributed/elastic/metrics/api.py\n",
            " in \"_call_impl  File Thread 0x\n",
            ", line \"  File 137/usr/lib/python3.10/multiprocessing/process.py in 00001517e05e2640wrapper\"\"/home/alex-zhao/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py (most recent call first):\n",
            "\"\n",
            ", line   <no Python frame>\n",
            ", line   File 314\n",
            " in 1736\"Thread 0x_bootstrap in /home/alex-zhao/.venv/lib/python3.10/site-packages/torch/distributed/elastic/agent/server/api.py\n",
            "\"_wrapped_call_impl, line 00001517e03e1640\n",
            "671 (most recent call first):\n",
            "  File  in   File   <no Python frame>\n",
            "\"_initialize_workers\"\n",
            "/tmp/ipykernel_1160500/161130724.py/usr/lib/python3.10/multiprocessing/popen_fork.py\n",
            "Thread 0x\"\", line , line   File 00001517dbfff6402671\" in /home/alex-zhao/.venv/lib/python3.10/site-packages/torch/distributed/elastic/metrics/api.py (most recent call first):\n",
            " in \"_launchtorch_dynamo_resume_in_forward_at_20, line \n",
            "\n",
            "137  File   File  in \"wrapper/usr/lib/python3.10/multiprocessing/popen_fork.py  File \"\n",
            "\"\"/usr/lib/python3.10/threading.py  File \"\", line , line /tmp/ipykernel_1160500/161130724.py/home/alex-zhao/.venv/lib/python3.10/site-packages/torch/distributed/elastic/agent/server/api.py324\"19, line \" in  in 849wait, line  in __init__\n",
            "\n",
            "20_invoke_run  File \n",
            " in \"  File torch_dynamo_resume_in_forward_at_20/usr/lib/python3.10/multiprocessing/context.py\"\n",
            "\"  File /home/alex-zhao/.venv/lib/python3.10/site-packages/torch/distributed/elastic/agent/server/api.py\"\"/usr/lib/python3.10/threading.py  File , line \", line /tmp/ipykernel_1160500/161130724.py\"281696\" in  in , line , line _Popenrun12607\n",
            "\n",
            " in  in   File   File \"\"forwardwait\n",
            "/usr/lib/python3.10/multiprocessing/process.py/home/alex-zhao/.venv/lib/python3.10/site-packages/torch/distributed/elastic/metrics/api.py\n",
            "  File \"\"\", line , line /home/alex-zhao/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py121  File  in 137\"start, line  in \"\n",
            "1747wrapper/home/alex-zhao/.venv/lib/python3.10/site-packages/tqdm/_monitor.py in   File _call_impl\n",
            "\"\"\n",
            "  File /home/alex-zhao/.venv/lib/python3.10/site-packages/torch/multiprocessing/spawn.py  File \", line \"\"/home/alex-zhao/.venv/lib/python3.10/site-packages/torch/distributed/launcher/api.py/home/alex-zhao/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py60, line  in \"\"263run, line , line  in 1736\n",
            "260start_process in  in   File launch_agent\n",
            "_wrapped_call_impl\"\n",
            "  File \n",
            "/usr/lib/python3.10/threading.py\"  File /home/alex-zhao/.venv/lib/python3.10/site-packages/torch/multiprocessing/spawn.py  File \"\"\"\", line , line /home/alex-zhao/.venv/lib/python3.10/site-packages/torch/distributed/launcher/api.py/home/alex-zhao/.venv/lib/python3.10/site-packages/torch/nn/parallel/distributed.py1016268\"\", line  in  in , line 1381459_bootstrap_innerstart_processes in  in \n",
            "\n",
            "__call__  File _run_ddp_forward\"\n",
            "\n",
            "  File /home/alex-zhao/.venv/lib/python3.10/site-packages/torch/distributed/elastic/multiprocessing/api.py  File \"  File \"\", line /home/alex-zhao/.venv/lib/python3.10/site-packages/accelerate/launchers.py\"/usr/lib/python3.10/threading.py658\"/home/alex-zhao/.venv/lib/python3.10/site-packages/torch/nn/parallel/distributed.py\" in \", line , line 245973, line  in  in 1643_startnotebook_launcher in _bootstrap\n",
            "\n",
            "forward\n",
            "  File   File \"\n",
            "\n",
            "\"Thread 0x/tmp/ipykernel_1160500/4060614896.py/home/alex-zhao/.venv/lib/python3.10/site-packages/torch/distributed/elastic/multiprocessing/api.py\"\"  File 00001517da7f3640, line , line \" (most recent call first):\n",
            "1485/home/alex-zhao/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py in  in \"<module>start, line   File 1747\n",
            "\n",
            " in   File _call_impl\"  File \n",
            "\"  File /home/alex-zhao/.venv/lib/python3.10/site-packages/torch/_inductor/compile_worker/subproc_pool.py\"/home/alex-zhao/.venv/lib/python3.10/site-packages/IPython/core/interactiveshell.py/home/alex-zhao/.venv/lib/python3.10/site-packages/torch/distributed/elastic/multiprocessing/__init__.py\"\"/home/alex-zhao/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py\"\", line , line 3577229 in , line \" in run_code47, line start_processes\n",
            " in 1736\n",
            "_recv_msg in   File \n",
            "  File _wrapped_call_impl\"\"\n",
            "/home/alex-zhao/.venv/lib/python3.10/site-packages/torch/distributed/elastic/agent/server/local_elastic_agent.py  File   File /home/alex-zhao/.venv/lib/python3.10/site-packages/IPython/core/interactiveshell.py\"\"\"\", line /home/alex-zhao/.venv/lib/python3.10/site-packages/torch/_dynamo/external_utils.py, line /home/alex-zhao/.venv/lib/python3.10/site-packages/torch/_inductor/compile_worker/subproc_pool.py343\"3517\" in , line  in _start_workers40, line run_ast_nodes153\n",
            " in \n",
            " in   File   File inner_read_thread\"\n",
            "/home/alex-zhao/.venv/lib/python3.10/site-packages/IPython/core/interactiveshell.py\"\n",
            "\"/home/alex-zhao/.venv/lib/python3.10/site-packages/torch/distributed/elastic/metrics/api.py  File \", line   File \", line 3334137/usr/lib/python3.10/threading.py\" in  in run_cell_async\"/home/alex-zhao/.venv/lib/python3.10/site-packages/torch/_dynamo/eval_frame.pywrapper\n",
            ", line \"\n",
            "953  File  in , line   File run\"465/home/alex-zhao/.venv/lib/python3.10/site-packages/IPython/core/async_helpers.py\"\n",
            " in \"/home/alex-zhao/.venv/lib/python3.10/site-packages/torch/distributed/elastic/agent/server/api.py, line \"_fn  File 128, line \n",
            " in \"671  File _pseudo_sync_runner/home/alex-zhao/.venv/lib/python3.10/site-packages/ipykernel/ipkernel.py\n",
            " in \"\"  File /tmp/ipykernel_1160500/3913905366.py\"_initialize_workers, line \"/home/alex-zhao/.venv/lib/python3.10/site-packages/IPython/core/interactiveshell.py\n",
            "\"766, line , line   File 54\" in  in training_functionrun_closure3130/home/alex-zhao/.venv/lib/python3.10/site-packages/torch/distributed/elastic/metrics/api.py\n",
            "\n",
            " in \"_run_cell  File , line \n",
            "\"137  File  in   File /home/alex-zhao/.venv/lib/python3.10/site-packages/torch/distributed/elastic/multiprocessing/errors/__init__.py\"\"/home/alex-zhao/.venv/lib/python3.10/site-packages/IPython/core/interactiveshell.pywrapper\"\", line \n",
            "/usr/lib/python3.10/threading.py355, line   File \" in , line 3075\"1016wrapper in /home/alex-zhao/.venv/lib/python3.10/site-packages/torch/distributed/elastic/agent/server/api.pyrun_cell in \n",
            "\"\n",
            "_bootstrap_inner  File \n",
            ", line   File \"  File \"/home/alex-zhao/.venv/lib/python3.10/site-packages/torch/distributed/elastic/multiprocessing/api.py/home/alex-zhao/.venv/lib/python3.10/site-packages/ipykernel/zmqshell.py\"849\"\", line  in , line /usr/lib/python3.10/threading.py611_invoke_run in 549\" in , line run_cell\n",
            "_wrap973\n",
            " in \n",
            "  File _bootstrap  File   File \"\n",
            "\"\"/home/alex-zhao/.venv/lib/python3.10/site-packages/torch/distributed/elastic/agent/server/api.py\n",
            "/home/alex-zhao/.venv/lib/python3.10/site-packages/torch/multiprocessing/spawn.py/home/alex-zhao/.venv/lib/python3.10/site-packages/ipykernel/ipkernel.py\"Current thread 0x\"\", line 0000151996ed21c0, line 696, line  (most recent call first):\n",
            "90 in 449  File  in run in \n",
            "\"  File /tmp/ipykernel_1160500/4248888456.py_wrapdo_execute\"/home/alex-zhao/.venv/lib/python3.10/site-packages/torch/distributed/elastic/metrics/api.py\", line 137 in \n",
            "  File \"\n",
            "wrapper\"\n",
            "  File /home/alex-zhao/.venv/lib/python3.10/site-packages/ipykernel/kernelbase.py, line   File \"\"\"19/home/alex-zhao/.venv/lib/python3.10/site-packages/torch/distributed/launcher/api.py, line /usr/lib/python3.10/multiprocessing/process.py in \"778torch_dynamo_resume_in_forward_at_16 in \", line \n",
            ", line 260  File  in execute_request108\"launch_agent\n",
            " in \n",
            "/tmp/ipykernel_1160500/4248888456.py  File run\"  File \", line \n",
            "\"/home/alex-zhao/.venv/lib/python3.10/site-packages/ipykernel/ipkernel.py14/home/alex-zhao/.venv/lib/python3.10/site-packages/torch/distributed/launcher/api.py\"\"  File  in , line , line \"/usr/lib/python3.10/multiprocessing/process.py362torch_dynamo_resume_in_forward_at_14138\n",
            "\" in  in , line execute_request__call__314\n",
            "  File \n",
            "  File  in \"  File \"_bootstrap/home/alex-zhao/.venv/lib/python3.10/site-packages/ipykernel/kernelbase.py/tmp/ipykernel_1160500/4248888456.py\"\"\n",
            "\", line /home/alex-zhao/.venv/lib/python3.10/site-packages/accelerate/launchers.py13  File , line \" in \"437, line forward245/usr/lib/python3.10/multiprocessing/popen_fork.py in \n",
            " in \"dispatch_shell  File \n",
            ", line \"notebook_launcher  File \n",
            "71/home/alex-zhao/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py\"  File  in \"/home/alex-zhao/.venv/lib/python3.10/site-packages/ipykernel/kernelbase.py\"_launch\", line , line /tmp/ipykernel_1160500/4060614896.py\n",
            "1747534\" in  in   File _call_impl, line \n",
            "process_one\"1  File \n",
            "/usr/lib/python3.10/multiprocessing/popen_fork.py in \"  File \"<module>/home/alex-zhao/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py\"\n",
            ", line \"/home/alex-zhao/.venv/lib/python3.10/site-packages/ipykernel/kernelbase.py19, line   File \" in 1736__init__, line  in \n",
            "\"545_wrapped_call_impl  File /home/alex-zhao/.venv/lib/python3.10/site-packages/IPython/core/interactiveshell.py in \n",
            "\"  File \"dispatch_queue, line \n",
            "3577\"/usr/lib/python3.10/multiprocessing/context.py in   File /tmp/ipykernel_1160500/161130724.py\"\"\"run_code, line , line /usr/lib/python3.10/asyncio/events.py\n",
            "\"28126, line  in   File  in \"80_Popentorch_dynamo_resume_in_forward_at_20/home/alex-zhao/.venv/lib/python3.10/site-packages/IPython/core/interactiveshell.py in \n",
            "_run\n",
            "\"\n",
            "  File , line \"  File   File 3517/usr/lib/python3.10/multiprocessing/process.py\"\" in \"/usr/lib/python3.10/asyncio/base_events.py/tmp/ipykernel_1160500/161130724.pyrun_ast_nodes, line \"\", line \n",
            "121, line 190920 in   File  in  in start\"_run_once\n",
            "/home/alex-zhao/.venv/lib/python3.10/site-packages/IPython/core/interactiveshell.pytorch_dynamo_resume_in_forward_at_20  File \n",
            "\"\n",
            "\"  File   File /home/alex-zhao/.venv/lib/python3.10/site-packages/torch/multiprocessing/spawn.py\", line \"/usr/lib/python3.10/asyncio/base_events.py/tmp/ipykernel_1160500/161130724.py\"3334\"\", line , line , line  in 60312263run_cell_async in  in  in \n",
            "run_foreverforwardstart_process\n",
            "  File \n",
            "\n",
            "  File   File \"\"  File /home/alex-zhao/.venv/lib/python3.10/site-packages/torch/multiprocessing/spawn.py\"/home/alex-zhao/.venv/lib/python3.10/site-packages/tornado/platform/asyncio.py\"\"/home/alex-zhao/.venv/lib/python3.10/site-packages/IPython/core/async_helpers.py\"/home/alex-zhao/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py, line \", line \"268205, line , line 1747 in  in 128 in startstart_processes in _call_impl\n",
            "\n",
            "\n",
            "_pseudo_sync_runner  File   File \n",
            "\"  File \"/home/alex-zhao/.venv/lib/python3.10/site-packages/torch/distributed/elastic/multiprocessing/api.py\"/home/alex-zhao/.venv/lib/python3.10/site-packages/ipykernel/kernelapp.py  File \"/home/alex-zhao/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py\"\", line /home/alex-zhao/.venv/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line , line 739658\"1736 in  in , line  in start_start3130_wrapped_call_impl\n",
            "\n",
            " in   File \n",
            "\"_run_cell/home/alex-zhao/.venv/lib/python3.10/site-packages/traitlets/config/application.py  File   File \n",
            "  File \"\"\"\", line /home/alex-zhao/.venv/lib/python3.10/site-packages/torch/nn/parallel/distributed.py/home/alex-zhao/.venv/lib/python3.10/site-packages/IPython/core/interactiveshell.py/home/alex-zhao/.venv/lib/python3.10/site-packages/torch/distributed/elastic/multiprocessing/api.py1075\" in \"\"launch_instance, line , line , line \n",
            "30751459485 in   File  in run_cell in \"\n",
            "_run_ddp_forwardstart/home/alex-zhao/.venv/lib/python3.10/site-packages/ipykernel_launcher.py\n",
            "\n",
            "  File \"  File   File , line \"\"18\"/home/alex-zhao/.venv/lib/python3.10/site-packages/torch/nn/parallel/distributed.py/home/alex-zhao/.venv/lib/python3.10/site-packages/torch/distributed/elastic/multiprocessing/__init__.py in /home/alex-zhao/.venv/lib/python3.10/site-packages/ipykernel/zmqshell.py<module>\"\"\"\n",
            ", line , line   File 2291643, line \" in  in 549/usr/lib/python3.10/runpy.pystart_processesforward in \"\n",
            "\n",
            "run_cell, line   File   File \n",
            "86\" in \"/home/alex-zhao/.venv/lib/python3.10/site-packages/torch/distributed/elastic/agent/server/local_elastic_agent.py  File \"\"_run_code/home/alex-zhao/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py/home/alex-zhao/.venv/lib/python3.10/site-packages/ipykernel/ipkernel.py, line \n",
            "343\"\" in   File , line \"1747/usr/lib/python3.10/runpy.py_start_workers, line  in \"_call_impl\n",
            "449\n",
            ", line  in   File 196  File  in \"do_execute\"_run_module_as_main/home/alex-zhao/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py\n",
            "\n",
            "/home/alex-zhao/.venv/lib/python3.10/site-packages/torch/distributed/elastic/metrics/api.py\"\", line , line 1736  File 137 in  in \"_wrapped_call_implwrapper/home/alex-zhao/.venv/lib/python3.10/site-packages/ipykernel/kernelbase.py\n",
            "\n",
            "\"  File , line   File 778\" in \"/home/alex-zhao/.venv/lib/python3.10/site-packages/torch/_dynamo/external_utils.py/home/alex-zhao/.venv/lib/python3.10/site-packages/torch/distributed/elastic/agent/server/api.py\"\", line execute_request, line \n",
            "40671 in  in   File inner\"_initialize_workers\n",
            "/home/alex-zhao/.venv/lib/python3.10/site-packages/ipykernel/ipkernel.py\n",
            "  File \"  File , line \"362/home/alex-zhao/.venv/lib/python3.10/site-packages/torch/distributed/elastic/metrics/api.py in \"\"execute_request/home/alex-zhao/.venv/lib/python3.10/site-packages/torch/_dynamo/eval_frame.py\n",
            ", line \"137  File , line  in 465\"wrapper in \n",
            "_fn/home/alex-zhao/.venv/lib/python3.10/site-packages/ipykernel/kernelbase.py  File \n",
            "\"\", line /home/alex-zhao/.venv/lib/python3.10/site-packages/torch/distributed/elastic/agent/server/api.py  File 437\" in \", line /tmp/ipykernel_1160500/3913905366.pydispatch_shell849\"\n",
            " in _invoke_run, line   File \n",
            "54\" in /home/alex-zhao/.venv/lib/python3.10/site-packages/ipykernel/kernelbase.py  File \"\"\n",
            "Extension modules: training_function/home/alex-zhao/.venv/lib/python3.10/site-packages/torch/distributed/elastic/agent/server/api.py, line \"zmq.backend.cython._zmq\n",
            "534, line   File  in 696\"process_one in \n",
            "/home/alex-zhao/.venv/lib/python3.10/site-packages/torch/distributed/elastic/multiprocessing/errors/__init__.pyrun\"  File \n",
            "\"  File /home/alex-zhao/.venv/lib/python3.10/site-packages/ipykernel/kernelbase.py, line \"\"/home/alex-zhao/.venv/lib/python3.10/site-packages/torch/distributed/elastic/metrics/api.py, line \"545355 in , line  in dispatch_queue137wrapper\n",
            " in \n",
            "wrapper  File   File \n",
            "\"  File /home/alex-zhao/.venv/lib/python3.10/site-packages/torch/distributed/elastic/multiprocessing/api.py\"\"/usr/lib/python3.10/asyncio/events.py/home/alex-zhao/.venv/lib/python3.10/site-packages/torch/distributed/launcher/api.py\"\"\", line , line 260, line 80 in 611 in launch_agent in \n",
            "_run_wrap\n",
            "  File \n",
            "\"/home/alex-zhao/.venv/lib/python3.10/site-packages/torch/distributed/launcher/api.py  File \"  File , line \"138/usr/lib/python3.10/asyncio/base_events.py\"\" in /home/alex-zhao/.venv/lib/python3.10/site-packages/torch/multiprocessing/spawn.py__call__, line \"\n",
            "1909  File  in , line \"90_run_once/home/alex-zhao/.venv/lib/python3.10/site-packages/accelerate/launchers.py in \n",
            "\", line   File , \"_wrap245tornado.speedups/usr/lib/python3.10/asyncio/base_events.py\n",
            " in \"  File notebook_launcher, line \n",
            "603 in   File run_forever\"\"\n",
            "/tmp/ipykernel_1160500/4060614896.py/usr/lib/python3.10/multiprocessing/process.py\"\"  File , line 1 in , line \"108/home/alex-zhao/.venv/lib/python3.10/site-packages/tornado/platform/asyncio.py<module> in \"run\n",
            "\n",
            "  File , line   File \"205\" in /usr/lib/python3.10/multiprocessing/process.py/home/alex-zhao/.venv/lib/python3.10/site-packages/IPython/core/interactiveshell.pystart\"\"\n",
            ", line , line   File 3577314 in  in _bootstraprun_code\"\n",
            "\n",
            "/home/alex-zhao/.venv/lib/python3.10/site-packages/ipykernel/kernelapp.py\"  File   File \"\", line /usr/lib/python3.10/multiprocessing/popen_fork.py739/home/alex-zhao/.venv/lib/python3.10/site-packages/IPython/core/interactiveshell.py\" in \"start\n",
            ", line , line 351771 in   File  in run_ast_nodes\n",
            "_launch\"  File \n",
            "/home/alex-zhao/.venv/lib/python3.10/site-packages/traitlets/config/application.py\"\"  File /home/alex-zhao/.venv/lib/python3.10/site-packages/IPython/core/interactiveshell.py\"\", line /usr/lib/python3.10/multiprocessing/popen_fork.py1075\", line  in , line 333419 in launch_instance,  in run_cell_async\n",
            "psutil._psutil_linux__init__\n",
            "\n",
            "  File   File \"  File \"/home/alex-zhao/.venv/lib/python3.10/site-packages/ipykernel_launcher.py, /home/alex-zhao/.venv/lib/python3.10/site-packages/IPython/core/async_helpers.pypsutil._psutil_posix\"\", line \"/usr/lib/python3.10/multiprocessing/context.py18, line \" in , line 128<module>281 in \n",
            " in _pseudo_sync_runner\n",
            "  File   File _Popen\", \n",
            "/home/alex-zhao/.venv/lib/python3.10/site-packages/IPython/core/interactiveshell.py_pydevd_bundle.pydevd_cython\"  File \"/usr/lib/python3.10/runpy.py, line \"\"3130/usr/lib/python3.10/multiprocessing/process.py in \", line _run_cell86\n",
            ", line  in   File 121\" in , _run_code/home/alex-zhao/.venv/lib/python3.10/site-packages/IPython/core/interactiveshell.pystartnumpy._core._multiarray_umath\n",
            "\n",
            "\", line 3075 in   File   File run_cell\"\"\n",
            "/home/alex-zhao/.venv/lib/python3.10/site-packages/torch/multiprocessing/spawn.py/usr/lib/python3.10/runpy.py,   File \"\"\"numpy._core._multiarray_tests, line /home/alex-zhao/.venv/lib/python3.10/site-packages/ipykernel/zmqshell.py, line 263\"196 in ,  in , line _run_module_as_mainnumpy.linalg._umath_linalgstart_process549\n",
            " in \n",
            "run_cell  File \n",
            "\"/home/alex-zhao/.venv/lib/python3.10/site-packages/torch/multiprocessing/spawn.py  File , \"\"torch._C, line /home/alex-zhao/.venv/lib/python3.10/site-packages/ipykernel/ipkernel.py268\" in , line , start_processes449torch._C._dynamo.autograd_compiler\n",
            " in   File do_execute, \"torch._C._dynamo.eval_frame/home/alex-zhao/.venv/lib/python3.10/site-packages/torch/distributed/elastic/multiprocessing/api.py\n",
            "\"  File \", , line /home/alex-zhao/.venv/lib/python3.10/site-packages/ipykernel/kernelbase.pytorch._C._dynamo.guards658\" in _start\n",
            ", line 778  File ,  in torch._C._dynamo.utils\"execute_request/home/alex-zhao/.venv/lib/python3.10/site-packages/torch/distributed/elastic/multiprocessing/api.py\n",
            "\"  File , torch._C._fft\", line /home/alex-zhao/.venv/lib/python3.10/site-packages/ipykernel/ipkernel.py485\",  in torch._C._linalg, line start362\n",
            " in execute_request  File , \n",
            "\"  File torch._C._nested\"/home/alex-zhao/.venv/lib/python3.10/site-packages/torch/distributed/elastic/multiprocessing/__init__.py/home/alex-zhao/.venv/lib/python3.10/site-packages/ipykernel/kernelbase.py\", \"torch._C._nn, line , line 437229 in  in , start_processesdispatch_shell\n",
            "torch._C._sparse\n",
            "  File   File \"\"/home/alex-zhao/.venv/lib/python3.10/site-packages/ipykernel/kernelbase.py, \"/home/alex-zhao/.venv/lib/python3.10/site-packages/torch/distributed/elastic/agent/server/local_elastic_agent.pytorch._C._special\", line 534 in process_one\n",
            ", line 343  File  in \"/home/alex-zhao/.venv/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 545_start_workers in \n",
            "dispatch_queue\n",
            "  File   File \"/usr/lib/python3.10/asyncio/events.py\"\", line 80/home/alex-zhao/.venv/lib/python3.10/site-packages/torch/distributed/elastic/metrics/api.py in \"_run\n",
            ", line   File \"137/usr/lib/python3.10/asyncio/base_events.py in \"wrapper\n",
            ", line 1909 in   File _run_once\"\n",
            "/home/alex-zhao/.venv/lib/python3.10/site-packages/torch/distributed/elastic/agent/server/api.py\"  File \"/usr/lib/python3.10/asyncio/base_events.py\", line , line 671603 in  in run_forever\n",
            "_initialize_workers  File \n",
            "\"/home/alex-zhao/.venv/lib/python3.10/site-packages/tornado/platform/asyncio.py\"  File , line \"205/home/alex-zhao/.venv/lib/python3.10/site-packages/torch/distributed/elastic/metrics/api.py in \"start, line \n",
            "137 in wrapper  File \n",
            "\"  File /home/alex-zhao/.venv/lib/python3.10/site-packages/ipykernel/kernelapp.py\"\", /home/alex-zhao/.venv/lib/python3.10/site-packages/torch/distributed/elastic/agent/server/api.py, line PIL._imaging\n",
            "Extension modules: \"739zmq.backend.cython._zmq in , line , startPIL._imagingft\n",
            "849 in _invoke_run  File \n",
            "  File \"\"/home/alex-zhao/.venv/lib/python3.10/site-packages/traitlets/config/application.py/home/alex-zhao/.venv/lib/python3.10/site-packages/torch/distributed/elastic/agent/server/api.py\"\", line 1075 in , line launch_instance696\n",
            " in run\n",
            "  File   File \"/home/alex-zhao/.venv/lib/python3.10/site-packages/torch/distributed/elastic/metrics/api.py\"\"/home/alex-zhao/.venv/lib/python3.10/site-packages/ipykernel_launcher.py, line \"137 in wrapper, line \n",
            "18 in <module>\n",
            "  File \"  File /home/alex-zhao/.venv/lib/python3.10/site-packages/torch/distributed/launcher/api.py\"\"/usr/lib/python3.10/runpy.py\", line , line 26086 in  in _run_code\n",
            "launch_agent\n",
            "  File \"/usr/lib/python3.10/runpy.py\"  File , line \"196/home/alex-zhao/.venv/lib/python3.10/site-packages/torch/distributed/launcher/api.py in \"_run_module_as_main\n",
            ", line 138 in __call__\n",
            ",   File numpy.random._common\"/home/alex-zhao/.venv/lib/python3.10/site-packages/accelerate/launchers.py\", numpy.random.bit_generator, line 245 in notebook_launcher\n",
            "  File \", /tmp/ipykernel_1160500/4060614896.pynumpy.random._bounded_integers\", line 1 in , <module>numpy.random._mt19937\n",
            "  File \"/home/alex-zhao/.venv/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", numpy.random.mtrand, line 3577 in run_code\n",
            "  File \"/home/alex-zhao/.venv/lib/python3.10/site-packages/IPython/core/interactiveshell.py, \"numpy.random._philox, line 3517 in run_ast_nodes\n",
            "  File \"/home/alex-zhao/.venv/lib/python3.10/site-packages/IPython/core/interactiveshell.py, \"numpy.random._pcg64, line 3334 in run_cell_async\n",
            ", numpy.random._sfc64  File \"/home/alex-zhao/.venv/lib/python3.10/site-packages/IPython/core/async_helpers.py\", line 128 in _pseudo_sync_runner, \n",
            "numpy.random._generator  File \"/home/alex-zhao/.venv/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3130 in _run_cell\n",
            "  File \"/home/alex-zhao/.venv/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3075 in run_cell\n",
            "  File \"/home/alex-zhao/.venv/lib/python3.10/site-packages/ipykernel/zmqshell.py\", line 549 in run_cell\n",
            "  File \"/home/alex-zhao/.venv/lib/python3.10/site-packages/ipykernel/ipkernel.py\", line 449 in do_execute\n",
            "  File \"/home/alex-zhao/.venv/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 778 in execute_request\n",
            "  File \"/home/alex-zhao/.venv/lib/python3.10/site-packages/ipykernel/ipkernel.py\", line \n",
            "Extension modules: 362zmq.backend.cython._zmq in execute_request\n",
            "  File \"/home/alex-zhao/.venv/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 437 in dispatch_shell\n",
            "  File \", /home/alex-zhao/.venv/lib/python3.10/site-packages/ipykernel/kernelbase.pykiwisolver._cext\", line 534 in process_one\n",
            "  File \"/home/alex-zhao/.venv/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 545 in dispatch_queue\n",
            "  File \"/usr/lib/python3.10/asyncio/events.py\", line 80 in _run\n",
            "  File \"/usr/lib/python3.10/asyncio/base_events.py\", line 1909 in _run_once\n",
            ",   File charset_normalizer.md\"/usr/lib/python3.10/asyncio/base_events.py, \"tornado.speedups, line 603 in run_forever\n",
            "  File \", /home/alex-zhao/.venv/lib/python3.10/site-packages/tornado/platform/asyncio.pyrequests.packages.charset_normalizer.md\", line 205 in start\n",
            "  File \", /home/alex-zhao/.venv/lib/python3.10/site-packages/ipykernel/kernelapp.pyrequests.packages.chardet.md\", line 739 in start\n",
            "  File \"/home/alex-zhao/.venv/lib/python3.10/site-packages/traitlets/config/application.py\", line 1075 in launch_instance, \n",
            "yaml._yaml  File \"/home/alex-zhao/.venv/lib/python3.10/site-packages/ipykernel_launcher.py\", , line tornado.speedups18 in <module>\n",
            "  File \"/usr/lib/python3.10/runpy.py\", , line pyarrow.lib86 in _run_code\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line , 196pandas._libs.tslibs.ccalendar in _run_module_as_main\n",
            ", pandas._libs.tslibs.np_datetime, pandas._libs.tslibs.dtypes, pandas._libs.tslibs.base, pandas._libs.tslibs.nattype, pandas._libs.tslibs.timezones, pandas._libs.tslibs.fields, pandas._libs.tslibs.timedeltas, pandas._libs.tslibs.tzconversion, pandas._libs.tslibs.timestamps, pandas._libs.properties, pandas._libs.tslibs.offsets, pandas._libs.tslibs.strptime, psutil._psutil_linux, pandas._libs.tslibs.parsing, , psutil._psutil_posixpandas._libs.tslibs.conversion, pandas._libs.tslibs.period, pandas._libs.tslibs.vectorized\n",
            "Extension modules: zmq.backend.cython._zmq, pandas._libs.ops_dispatch, _pydevd_bundle.pydevd_cython, pandas._libs.missing, pandas._libs.hashtable, pandas._libs.algos, pandas._libs.interval, pandas._libs.lib, numpy._core._multiarray_umath, pyarrow._compute, pandas._libs.ops, pandas._libs.hashing, pandas._libs.arrays, , pandas._libs.tslibnumpy._core._multiarray_tests, pandas._libs.sparse, tornado.speedups, pandas._libs.internals, pandas._libs.indexing, pandas._libs.index, numpy.linalg._umath_linalg, pandas._libs.writers, pandas._libs.join, pandas._libs.window.aggregations, pandas._libs.window.indexers, pandas._libs.reshape, pandas._libs.groupby, torch._C, pandas._libs.json, torch._C._dynamo.autograd_compiler, pandas._libs.parsers, torch._C._dynamo.eval_frame, pandas._libs.testing, torch._C._dynamo.guards, torch._C._dynamo.utils, torch._C._fft, pyarrow._parquet, torch._C._linalg, pyarrow._fs, psutil._psutil_linux, torch._C._nested, pyarrow._azurefs, psutil._psutil_posix, torch._C._nn, pyarrow._hdfs, pyarrow._gcsfs, torch._C._sparse, pyarrow._s3fs, torch._C._special, _pydevd_bundle.pydevd_cython, multidict._multidict, yarl._quoting_c, numpy._core._multiarray_umath, propcache._helpers_c, numpy._core._multiarray_tests, aiohttp._http_writer, numpy.linalg._umath_linalg, aiohttp._http_parser, torch._C, aiohttp._websocket.mask, , torch._C._dynamo.autograd_compileraiohttp._websocket.reader_c, torch._C._dynamo.eval_frame, torch._C._dynamo.guards, frozenlist._frozenlist, torch._C._dynamo.utils, torch._C._fft, xxhash._xxhash, torch._C._linalg, , torch._C._nestedpyarrow._json, torch._C._nn, pyarrow._acero, torch._C._sparse, pyarrow._csv, torch._C._special, pyarrow._dataset, pyarrow._dataset_orc, pyarrow._parquet_encryption, pyarrow._dataset_parquet_encryption, pyarrow._dataset_parquet, markupsafe._speedups, sentencepiece._sentencepiece, cuda_utils, __triton_launcher (total: 104)\n",
            ", PIL._imaging, PIL._imagingft, psutil._psutil_linux, psutil._psutil_posix, _pydevd_bundle.pydevd_cython, numpy._core._multiarray_umath, numpy._core._multiarray_tests, numpy.linalg._umath_linalg, PIL._imaging, torch._C, PIL._imagingft, torch._C._dynamo.autograd_compiler, torch._C._dynamo.eval_frame, torch._C._dynamo.guards, torch._C._dynamo.utils, torch._C._fft, torch._C._linalg, torch._C._nested, torch._C._nn, torch._C._sparse, torch._C._special, numpy.random._common, numpy.random.bit_generator, numpy.random._bounded_integers, numpy.random._mt19937, numpy.random.mtrand, numpy.random._philox, numpy.random._pcg64, numpy.random._sfc64, numpy.random._generator, PIL._imaging, PIL._imagingft, kiwisolver._cext, numpy.random._common, numpy.random.bit_generator, numpy.random._bounded_integers, numpy.random._mt19937, charset_normalizer.md, numpy.random.mtrand, numpy.random._philox, numpy.random._pcg64, requests.packages.charset_normalizer.md, numpy.random._sfc64, requests.packages.chardet.md, numpy.random._generator, yaml._yaml, pyarrow.lib, pandas._libs.tslibs.ccalendar, pandas._libs.tslibs.np_datetime, pandas._libs.tslibs.dtypes, pandas._libs.tslibs.base, pandas._libs.tslibs.nattype, pandas._libs.tslibs.timezones, pandas._libs.tslibs.fields, pandas._libs.tslibs.timedeltas, pandas._libs.tslibs.tzconversion, pandas._libs.tslibs.timestamps, pandas._libs.properties, pandas._libs.tslibs.offsets, pandas._libs.tslibs.strptime, pandas._libs.tslibs.parsing, pandas._libs.tslibs.conversion, pandas._libs.tslibs.period, pandas._libs.tslibs.vectorized, pandas._libs.ops_dispatch, pandas._libs.missing, numpy.random._common, pandas._libs.hashtable, , numpy.random.bit_generatorpandas._libs.algos, , pandas._libs.intervalnumpy.random._bounded_integers, numpy.random._mt19937, pandas._libs.lib, numpy.random.mtrand, numpy.random._philox, numpy.random._pcg64, pyarrow._compute, numpy.random._sfc64, numpy.random._generator, pandas._libs.ops, pandas._libs.hashing, pandas._libs.arrays, kiwisolver._cext, pandas._libs.tslib, pandas._libs.sparse, pandas._libs.internals, pandas._libs.indexing, pandas._libs.index, pandas._libs.writers, pandas._libs.join, pandas._libs.window.aggregations, pandas._libs.window.indexers, pandas._libs.reshape, charset_normalizer.md, pandas._libs.groupby, requests.packages.charset_normalizer.md, requests.packages.chardet.md, pandas._libs.json, pandas._libs.parsers, pandas._libs.testing, , kiwisolver._cextyaml._yaml, pyarrow._parquet, pyarrow._fs, pyarrow._azurefs, pyarrow._hdfs, pyarrow._gcsfs, pyarrow._s3fs, pyarrow.lib, multidict._multidict, pandas._libs.tslibs.ccalendar, pandas._libs.tslibs.np_datetime, pandas._libs.tslibs.dtypes, charset_normalizer.md, pandas._libs.tslibs.base, , yarl._quoting_cpandas._libs.tslibs.nattype, propcache._helpers_c, requests.packages.charset_normalizer.md, , pandas._libs.tslibs.timezonesrequests.packages.chardet.md, pandas._libs.tslibs.fields, pandas._libs.tslibs.timedeltas, aiohttp._http_writer, pandas._libs.tslibs.tzconversion, aiohttp._http_parser, pandas._libs.tslibs.timestamps, aiohttp._websocket.mask, pandas._libs.properties, aiohttp._websocket.reader_c, pandas._libs.tslibs.offsets, pandas._libs.tslibs.strptime, pandas._libs.tslibs.parsing, yaml._yaml, pandas._libs.tslibs.conversion, frozenlist._frozenlist, pandas._libs.tslibs.period, pandas._libs.tslibs.vectorized, pandas._libs.ops_dispatch, pandas._libs.missing, pandas._libs.hashtable, pandas._libs.algos, pandas._libs.interval, xxhash._xxhash, pandas._libs.lib, pyarrow._compute, pyarrow._json, pandas._libs.ops, pyarrow._acero, pyarrow.lib, pyarrow._csv, pyarrow._dataset, pandas._libs.hashing, pyarrow._dataset_orc, , pandas._libs.arrays, pyarrow._parquet_encryptionpandas._libs.tslibs.ccalendar, pandas._libs.tslibs.np_datetime, pyarrow._dataset_parquet_encryption, , pyarrow._dataset_parquetpandas._libs.tslibs.dtypes, pandas._libs.tslibs.base, pandas._libs.tslib, pandas._libs.tslibs.nattype, pandas._libs.sparse, pandas._libs.tslibs.timezones, markupsafe._speedups, pandas._libs.tslibs.fields, pandas._libs.internals, pandas._libs.tslibs.timedeltas, pandas._libs.indexing, pandas._libs.tslibs.tzconversion, pandas._libs.index, pandas._libs.tslibs.timestamps, pandas._libs.writers, pandas._libs.properties, pandas._libs.tslibs.offsets, pandas._libs.join, pandas._libs.tslibs.strptime, pandas._libs.tslibs.parsing, pandas._libs.tslibs.conversion, pandas._libs.tslibs.period, pandas._libs.tslibs.vectorized, pandas._libs.ops_dispatch, , sentencepiece._sentencepiecepandas._libs.window.aggregations, pandas._libs.missing, pandas._libs.window.indexers, pandas._libs.hashtable, pandas._libs.algos, , pandas._libs.reshapepandas._libs.interval, pandas._libs.lib, pandas._libs.groupby, pyarrow._compute, pandas._libs.ops, pandas._libs.json, pandas._libs.parsers, pandas._libs.hashing, pandas._libs.testing, pandas._libs.arrays, pandas._libs.tslib, pandas._libs.sparse, pandas._libs.internals, pandas._libs.indexing, pandas._libs.index, pandas._libs.writers, pandas._libs.join, pyarrow._parquet, pyarrow._fs, pyarrow._azurefs, , pyarrow._hdfspandas._libs.window.aggregations, pyarrow._gcsfs, pandas._libs.window.indexers, pyarrow._s3fs, pandas._libs.reshape, cuda_utils, , __triton_launcher, multidict._multidictpandas._libs.groupby (total: 104)\n",
            ", , yarl._quoting_cpandas._libs.json, , propcache._helpers_cpandas._libs.parsers, pandas._libs.testing, aiohttp._http_writer, aiohttp._http_parser, aiohttp._websocket.mask, aiohttp._websocket.reader_c, frozenlist._frozenlist, pyarrow._parquet, pyarrow._fs, xxhash._xxhash, pyarrow._azurefs, pyarrow._hdfs, pyarrow._gcsfs, pyarrow._s3fs, , pyarrow._jsonmultidict._multidict, pyarrow._acero, pyarrow._csv, yarl._quoting_c, pyarrow._dataset, propcache._helpers_c, pyarrow._dataset_orc, pyarrow._parquet_encryption, pyarrow._dataset_parquet_encryption, aiohttp._http_writer, pyarrow._dataset_parquet, aiohttp._http_parser, Fatal Python error: aiohttp._websocket.maskSegmentation fault\n",
            "\n",
            "Thread 0x, aiohttp._websocket.reader_c00001517e0de6640 (most recent call first):\n",
            "  <no Python frame>\n",
            "\n",
            "Thread 0x, markupsafe._speedups00001517e0fe7640 (most recent call first):\n",
            "  <no Python frame>\n",
            "\n",
            "Thread 0x00001517e0be5640 (most recent call first):\n",
            "  <no Python frame>\n",
            "\n",
            "Thread 0x00001517e11e8640 (most recent call first):\n",
            "  <no Python frame>\n",
            "\n",
            "Thread 0x00001517e07e3640 (most recent call first):\n",
            "  <no Python frame>\n",
            "\n",
            "Thread 0x, frozenlist._frozenlist00001517e05e2640 (most recent call first):\n",
            "  <no Python frame>\n",
            "\n",
            "Thread 0x00001517e09e4640 (most recent call first):\n",
            "  <no Python frame>\n",
            "\n",
            "Thread 0x00001517e03e1640 (most recent call first):\n",
            "  <no Python frame>\n",
            "\n",
            "Thread 0x00001517dbfff640 (most recent call first):\n",
            "  File \"/usr/lib/python3.10/threading.py\", line 324 in wait\n",
            "  File \"/usr/lib/python3.10/threading.py\", line 607 in wait\n",
            "  File \"/home/alex-zhao/.venv/lib/python3.10/site-packages/tqdm/_monitor.py\", line 60 in run\n",
            ",   File xxhash._xxhash\"/usr/lib/python3.10/threading.py\", line 1016 in _bootstrap_inner\n",
            "  File \"/usr/lib/python3.10/threading.py\", line 973 in _bootstrap\n",
            "\n",
            "Thread 0x00001517da7f3640 (most recent call first):\n",
            "  File \", /home/alex-zhao/.venv/lib/python3.10/site-packages/torch/_inductor/compile_worker/subproc_pool.pysentencepiece._sentencepiece\", line 47 in _recv_msg\n",
            "  File \"/home/alex-zhao/.venv/lib/python3.10/site-packages/torch/_inductor/compile_worker/subproc_pool.py\", line 153 in , _read_threadpyarrow._json\n",
            "  File \"/usr/lib/python3.10/threading.py\", line 953 in run\n",
            "  File \"/home/alex-zhao/.venv/lib/python3.10/site-packages/ipykernel/ipkernel.py\", line 766 in run_closure\n",
            "  File \"/usr/lib/python3.10/threading.py\", line 1016,  in pyarrow._acero_bootstrap_inner\n",
            "  File \"/usr/lib/python3.10/threading.py\", line 973 in _bootstrap\n",
            "\n",
            ", Current thread 0xpyarrow._csv0000151996ed21c0 (most recent call first):\n",
            "  File \"/tmp/ipykernel_1160500/4248888456.py\", line 19 in torch_dynamo_resume_in_forward_at_16\n",
            ",   File pyarrow._dataset\"/tmp/ipykernel_1160500/4248888456.py\", line 14 in torch_dynamo_resume_in_forward_at_14\n",
            "  File , pyarrow._dataset_orc\"/tmp/ipykernel_1160500/4248888456.py\", line 13 in forward\n",
            ", pyarrow._parquet_encryption  File \"/home/alex-zhao/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1747 in _call_impl, \n",
            "pyarrow._dataset_parquet_encryption  File \"/home/alex-zhao/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py\", line , 1736pyarrow._dataset_parquet in _wrapped_call_impl\n",
            "  File \"/tmp/ipykernel_1160500/161130724.py\", line 26 in torch_dynamo_resume_in_forward_at_20\n",
            "  File \"/tmp/ipykernel_1160500/161130724.py\", line 20 in torch_dynamo_resume_in_forward_at_20\n",
            "  File \"/tmp/ipykernel_1160500/161130724.py\", line 12 in forward\n",
            "  File \"/home/alex-zhao/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1747 in _call_impl\n",
            "  File \"/home/alex-zhao/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1736 in _wrapped_call_impl\n",
            "  File \"/home/alex-zhao/.venv/lib/python3.10/site-packages/torch/nn/parallel/distributed.py\", line 1459 in _run_ddp_forward\n",
            "  File \"/home/alex-zhao/.venv/lib/python3.10/site-packages/torch/nn/parallel/distributed.py\", , line markupsafe._speedups1643 in forward\n",
            "  File \"/home/alex-zhao/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1747 in _call_impl\n",
            "  File \"/home/alex-zhao/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1736 in _wrapped_call_impl\n",
            "  File \"/home/alex-zhao/.venv/lib/python3.10/site-packages/torch/_dynamo/external_utils.py\", line 40 in inner\n",
            "  File \"/home/alex-zhao/.venv/lib/python3.10/site-packages/torch/_dynamo/eval_frame.py\", line 465 in _fn\n",
            "  File \"/tmp/ipykernel_1160500/3913905366.py\", line 54 in training_function\n",
            "  File \"/home/alex-zhao/.venv/lib/python3.10/site-packages/torch/distributed/elastic/multiprocessing/errors/__init__.py\", line 355 in wrapper\n",
            "  File \"/home/alex-zhao/.venv/lib/python3.10/site-packages/torch/distributed/elastic/multiprocessing/api.py\", line 611 in _wrap\n",
            "  File \"/home/alex-zhao/.venv/lib/python3.10/site-packages/torch/multiprocessing/spawn.py\", line 90 in _wrap\n",
            "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 108 in run\n",
            "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 314 in _bootstrap\n",
            "  File \"/usr/lib/python3.10/multiprocessing/popen_fork.py\", line 71 in _launch\n",
            "  File \"/usr/lib/python3.10/multiprocessing/popen_fork.py\", line 19 in __init__\n",
            "  File \"/usr/lib/python3.10/multiprocessing/context.py\", line 281 in _Popen\n",
            "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 121 in start\n",
            "  File \"/home/alex-zhao/.venv/lib/python3.10/site-packages/torch/multiprocessing/spawn.py\", line 263 in start_process\n",
            ",   File sentencepiece._sentencepiece\"/home/alex-zhao/.venv/lib/python3.10/site-packages/torch/multiprocessing/spawn.py\", line 268 in start_processes\n",
            "  File \"/home/alex-zhao/.venv/lib/python3.10/site-packages/torch/distributed/elastic/multiprocessing/api.py\", line 658 in _start\n",
            "  File \"/home/alex-zhao/.venv/lib/python3.10/site-packages/torch/distributed/elastic/multiprocessing/api.py\", line 485 in start\n",
            "  File \"/home/alex-zhao/.venv/lib/python3.10/site-packages/torch/distributed/elastic/multiprocessing/__init__.py\", line 229 in start_processes\n",
            "  File \"/home/alex-zhao/.venv/lib/python3.10/site-packages/torch/distributed/elastic/agent/server/local_elastic_agent.py\", line 343 in _start_workers\n",
            "  File \"/home/alex-zhao/.venv/lib/python3.10/site-packages/torch/distributed/elastic/metrics/api.py\", line 137 in wrapper\n",
            "  File \"/home/alex-zhao/.venv/lib/python3.10/site-packages/torch/distributed/elastic/agent/server/api.py\", line 671 in _initialize_workers\n",
            "  File \"/home/alex-zhao/.venv/lib/python3.10/site-packages/torch/distributed/elastic/metrics/api.py\", line 137 in wrapper\n",
            "  File \"/home/alex-zhao/.venv/lib/python3.10/site-packages/torch/distributed/elastic/agent/server/api.py\", line 849 in _invoke_run\n",
            "  File \"/home/alex-zhao/.venv/lib/python3.10/site-packages/torch/distributed/elastic/agent/server/api.py\", line 696 in run\n",
            "  File \"/home/alex-zhao/.venv/lib/python3.10/site-packages/torch/distributed/elastic/metrics/api.py\", line 137 in wrapper\n",
            "  File \"/home/alex-zhao/.venv/lib/python3.10/site-packages/torch/distributed/launcher/api.py\", line 260 in launch_agent\n",
            "  File \"/home/alex-zhao/.venv/lib/python3.10/site-packages/torch/distributed/launcher/api.py\", line 138 in __call__\n",
            "  File \"/home/alex-zhao/.venv/lib/python3.10/site-packages/accelerate/launchers.py\", line 245 in notebook_launcher\n",
            "  File \"/tmp/ipykernel_1160500/4060614896.py\", line 1 in <module>\n",
            "  File \"/home/alex-zhao/.venv/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3577 in run_code\n",
            "  File \"/home/alex-zhao/.venv/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3517 in run_ast_nodes\n",
            "  File \"/home/alex-zhao/.venv/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3334 in run_cell_async\n",
            "  File \"/home/alex-zhao/.venv/lib/python3.10/site-packages/IPython/core/async_helpers.py\", line 128 in _pseudo_sync_runner\n",
            "  File \"/home/alex-zhao/.venv/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3130 in _run_cell\n",
            "  File \"/home/alex-zhao/.venv/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3075 in run_cell\n",
            "  File \"/home/alex-zhao/.venv/lib/python3.10/site-packages/ipykernel/zmqshell.py\", line 549 in run_cell\n",
            "  File \"/home/alex-zhao/.venv/lib/python3.10/site-packages/ipykernel/ipkernel.py\", line 449 in do_execute\n",
            "  File \"/home/alex-zhao/.venv/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 778 in execute_request\n",
            "  File \"/home/alex-zhao/.venv/lib/python3.10/site-packages/ipykernel/ipkernel.py\", line 362 in execute_request\n",
            "  File \"/home/alex-zhao/.venv/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 437 in dispatch_shell\n",
            "  File \"/home/alex-zhao/.venv/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 534 in process_one\n",
            "  File \"/home/alex-zhao/.venv/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 545 in dispatch_queue\n",
            "  File \"/usr/lib/python3.10/asyncio/events.py\", line 80 in _run\n",
            "  File \"/usr/lib/python3.10/asyncio/base_events.py\", line 1909 in _run_once\n",
            "  File \"/usr/lib/python3.10/asyncio/base_events.py\", line 603 in run_forever\n",
            "  File \"/home/alex-zhao/.venv/lib/python3.10/site-packages/tornado/platform/asyncio.py\", line 205 in start\n",
            "  File \"/home/alex-zhao/.venv/lib/python3.10/site-packages/ipykernel/kernelapp.py\", line 739 in start\n",
            "  File \"/home/alex-zhao/.venv/lib/python3.10/site-packages/traitlets/config/application.py\", line 1075 in launch_instance\n",
            "  File \"/home/alex-zhao/.venv/lib/python3.10/site-packages/ipykernel_launcher.py\", line 18 in <module>\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 86 in _run_code\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 196 in _run_module_as_main\n",
            ", cuda_utils, __triton_launcher (total: 104)\n",
            "\n",
            "Extension modules: zmq.backend.cython._zmq, cuda_utils, __triton_launcher (total: 104)\n",
            ", tornado.speedupsFatal Python error: Segmentation fault\n",
            "\n",
            "Thread 0x00001517e11e8640 (most recent call first):\n",
            "  <no Python frame>\n",
            "\n",
            "Thread 0x00001517e0fe7640 (most recent call first):\n",
            "  <no Python frame>\n",
            "\n",
            "Thread 0x00001517e0de6640 (most recent call first):\n",
            "  <no Python frame>\n",
            "\n",
            "Thread 0x00001517e0be5640 (most recent call first):\n",
            "  <no Python frame>\n",
            "\n",
            "Thread 0x00001517e09e4640 (most recent call first):\n",
            "  <no Python frame>\n",
            "\n",
            "Thread 0x00001517e07e3640 (most recent call first):\n",
            "  <no Python frame>\n",
            "\n",
            "Thread 0x00001517e05e2640 (most recent call first):\n",
            "  <no Python frame>\n",
            "\n",
            "Thread 0x00001517e03e1640 (most recent call first):\n",
            "  <no Python frame>\n",
            "\n",
            "Thread 0x00001517dbfff640 (most recent call first):\n",
            "  File \", /usr/lib/python3.10/threading.pypsutil._psutil_linux\", line 324 in , psutil._psutil_posixwait\n",
            "  File \"/usr/lib/python3.10/threading.py\", line 607 in wait\n",
            "  File \"/home/alex-zhao/.venv/lib/python3.10/site-packages/tqdm/_monitor.py\", line 60 in run\n",
            "  File \"/usr/lib/python3.10/threading.py\", line 1016 in _bootstrap_inner\n",
            "  File \"/usr/lib/python3.10/threading.py\", line 973 in _bootstrap\n",
            "\n",
            "Thread 0x00001517da7f3640 (most recent call first):\n",
            "  File \"/home/alex-zhao/.venv/lib/python3.10/site-packages/torch/_inductor/compile_worker/subproc_pool.py\", line 47 in _recv_msg\n",
            "  File \"/home/alex-zhao/.venv/lib/python3.10/site-packages/torch/_inductor/compile_worker/subproc_pool.py\", line 153 in _read_thread\n",
            "  File \"/usr/lib/python3.10/threading.py\", line 953 in run, \n",
            "_pydevd_bundle.pydevd_cython  File \"/home/alex-zhao/.venv/lib/python3.10/site-packages/ipykernel/ipkernel.py\", line 766 in run_closure\n",
            "  File \"/usr/lib/python3.10/threading.py\", line 1016 in _bootstrap_inner\n",
            "  File \"/usr/lib/python3.10/threading.py\", line 973 in _bootstrap\n",
            "\n",
            "Current thread 0x0000151996ed21c0 (most recent call first):\n",
            "  File \"/tmp/ipykernel_1160500/4248888456.py\", line 19 in torch_dynamo_resume_in_forward_at_16\n",
            "  File \"/tmp/ipykernel_1160500/4248888456.py\", line 14 in torch_dynamo_resume_in_forward_at_14\n",
            "  File \"/tmp/ipykernel_1160500/4248888456.py\", line 13 in forward\n",
            "  File \"/home/alex-zhao/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1747 in _call_impl\n",
            "  File \"/home/alex-zhao/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1736 in _wrapped_call_impl\n",
            "  File \"/tmp/ipykernel_1160500/161130724.py\", line 26 in torch_dynamo_resume_in_forward_at_20\n",
            "  File \"/tmp/ipykernel_1160500/161130724.py\", line 20 in torch_dynamo_resume_in_forward_at_20\n",
            "  File \"/tmp/ipykernel_1160500/161130724.py\", line 12 in forward\n",
            "  File \"/home/alex-zhao/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1747 in _call_impl\n",
            "  File \"/home/alex-zhao/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1736 in _wrapped_call_impl\n",
            "  File \"/home/alex-zhao/.venv/lib/python3.10/site-packages/torch/nn/parallel/distributed.py\", line 1459 in _run_ddp_forward\n",
            ",   File numpy._core._multiarray_umath\"/home/alex-zhao/.venv/lib/python3.10/site-packages/torch/nn/parallel/distributed.py\", line 1643 in forward\n",
            "  File \"/home/alex-zhao/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1747 in _call_impl\n",
            "  File \"/home/alex-zhao/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1736 in _wrapped_call_impl\n",
            "  File \"/home/alex-zhao/.venv/lib/python3.10/site-packages/torch/_dynamo/external_utils.py, \"numpy._core._multiarray_tests, line 40 in inner\n",
            "  File \"/home/alex-zhao/.venv/lib/python3.10/site-packages/torch/_dynamo/eval_frame.py\", line 465,  in numpy.linalg._umath_linalg_fn\n",
            "  File \"/tmp/ipykernel_1160500/3913905366.py\", line 54 in , torch._Ctraining_function\n",
            "  File , torch._C._dynamo.autograd_compiler, torch._C._dynamo.eval_frame, torch._C._dynamo.guards\", /home/alex-zhao/.venv/lib/python3.10/site-packages/torch/distributed/elastic/multiprocessing/errors/__init__.pytorch._C._dynamo.utils\", torch._C._fft, line , 355torch._C._linalg in wrapper\n",
            ", torch._C._nested  File \"/home/alex-zhao/.venv/lib/python3.10/site-packages/torch/distributed/elastic/multiprocessing/api.py\", torch._C._nn, line 611,  in torch._C._sparse_wrap\n",
            ", torch._C._special  File \"/home/alex-zhao/.venv/lib/python3.10/site-packages/torch/multiprocessing/spawn.py\", line 90 in _wrap\n",
            "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 108 in run\n",
            "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 314 in _bootstrap\n",
            "  File \"/usr/lib/python3.10/multiprocessing/popen_fork.py\", line 71 in _launch\n",
            "  File \"/usr/lib/python3.10/multiprocessing/popen_fork.py\", line 19 in __init__\n",
            "  File \"/usr/lib/python3.10/multiprocessing/context.py\", line 281 in _Popen\n",
            "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 121 in start\n",
            "  File \"/home/alex-zhao/.venv/lib/python3.10/site-packages/torch/multiprocessing/spawn.py\", line 263 in start_process\n",
            "  File \"/home/alex-zhao/.venv/lib/python3.10/site-packages/torch/multiprocessing/spawn.py\", line 268 in start_processes\n",
            "  File \"/home/alex-zhao/.venv/lib/python3.10/site-packages/torch/distributed/elastic/multiprocessing/api.py\", line 658 in _start\n",
            "  File \"/home/alex-zhao/.venv/lib/python3.10/site-packages/torch/distributed/elastic/multiprocessing/api.py\", line 485 in start\n",
            "  File \"/home/alex-zhao/.venv/lib/python3.10/site-packages/torch/distributed/elastic/multiprocessing/__init__.py\", line 229 in start_processes\n",
            "  File \"/home/alex-zhao/.venv/lib/python3.10/site-packages/torch/distributed/elastic/agent/server/local_elastic_agent.py\", line 343 in _start_workers\n",
            "  File \"/home/alex-zhao/.venv/lib/python3.10/site-packages/torch/distributed/elastic/metrics/api.py\", line 137 in wrapper\n",
            "  File \"/home/alex-zhao/.venv/lib/python3.10/site-packages/torch/distributed/elastic/agent/server/api.py\", line 671 in _initialize_workers\n",
            "  File \"/home/alex-zhao/.venv/lib/python3.10/site-packages/torch/distributed/elastic/metrics/api.py\", line 137 in wrapper\n",
            "  File \"/home/alex-zhao/.venv/lib/python3.10/site-packages/torch/distributed/elastic/agent/server/api.py\", line 849 in _invoke_run\n",
            "  File \"/home/alex-zhao/.venv/lib/python3.10/site-packages/torch/distributed/elastic/agent/server/api.py\", line 696 in run\n",
            "  File \"/home/alex-zhao/.venv/lib/python3.10/site-packages/torch/distributed/elastic/metrics/api.py\", line 137 in wrapper\n",
            "  File \"/home/alex-zhao/.venv/lib/python3.10/site-packages/torch/distributed/launcher/api.py\", line 260 in launch_agent\n",
            "  File \"/home/alex-zhao/.venv/lib/python3.10/site-packages/torch/distributed/launcher/api.py\", line , 138PIL._imaging in __call__\n",
            "  File \"/home/alex-zhao/.venv/lib/python3.10/site-packages/accelerate/launchers.py\", line 245,  in PIL._imagingftnotebook_launcher\n",
            "  File \"/tmp/ipykernel_1160500/4060614896.py\", line 1 in <module>\n",
            "  File \"/home/alex-zhao/.venv/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3577 in run_code\n",
            "  File \"/home/alex-zhao/.venv/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3517 in run_ast_nodes\n",
            "  File \"/home/alex-zhao/.venv/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3334 in run_cell_async\n",
            "  File \"/home/alex-zhao/.venv/lib/python3.10/site-packages/IPython/core/async_helpers.py\", line 128 in _pseudo_sync_runner\n",
            "  File \"/home/alex-zhao/.venv/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3130 in _run_cell\n",
            "  File \"/home/alex-zhao/.venv/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3075 in run_cell\n",
            "  File \"/home/alex-zhao/.venv/lib/python3.10/site-packages/ipykernel/zmqshell.py\", line 549 in run_cell\n",
            "  File \"/home/alex-zhao/.venv/lib/python3.10/site-packages/ipykernel/ipkernel.py\", line 449 in do_execute\n",
            "  File \"/home/alex-zhao/.venv/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 778 in execute_request\n",
            "  File \"/home/alex-zhao/.venv/lib/python3.10/site-packages/ipykernel/ipkernel.py\", line 362 in execute_request\n",
            "  File \"/home/alex-zhao/.venv/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 437 in dispatch_shell\n",
            "  File \"/home/alex-zhao/.venv/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 534 in process_one\n",
            "  File \"/home/alex-zhao/.venv/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 545 in dispatch_queue\n",
            "  File \"/usr/lib/python3.10/asyncio/events.py\", line 80 in _run\n",
            "  File \"/usr/lib/python3.10/asyncio/base_events.py\", line 1909 in _run_once\n",
            "  File \"/usr/lib/python3.10/asyncio/base_events.py\", line 603 in run_forever\n",
            "  File \"/home/alex-zhao/.venv/lib/python3.10/site-packages/tornado/platform/asyncio.py\", line 205 in start\n",
            "  File \"/home/alex-zhao/.venv/lib/python3.10/site-packages/ipykernel/kernelapp.py\", line 739 in start\n",
            "  File \"/home/alex-zhao/.venv/lib/python3.10/site-packages/traitlets/config/application.py\", line 1075 in launch_instance\n",
            "  File \"/home/alex-zhao/.venv/lib/python3.10/site-packages/ipykernel_launcher.py\", line 18 in <module>\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 86 in _run_code\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 196 in _run_module_as_main\n",
            ", numpy.random._common, numpy.random.bit_generator, numpy.random._bounded_integers, numpy.random._mt19937, numpy.random.mtrand, numpy.random._philox, numpy.random._pcg64, numpy.random._sfc64, numpy.random._generator\n",
            "Extension modules: zmq.backend.cython._zmq, kiwisolver._cext, tornado.speedups, charset_normalizer.md, requests.packages.charset_normalizer.md, requests.packages.chardet.md, yaml._yaml, pyarrow.lib, pandas._libs.tslibs.ccalendar, pandas._libs.tslibs.np_datetime, pandas._libs.tslibs.dtypes, pandas._libs.tslibs.base, pandas._libs.tslibs.nattype, pandas._libs.tslibs.timezones, pandas._libs.tslibs.fields, pandas._libs.tslibs.timedeltas, pandas._libs.tslibs.tzconversion, pandas._libs.tslibs.timestamps, pandas._libs.properties, pandas._libs.tslibs.offsets, pandas._libs.tslibs.strptime, pandas._libs.tslibs.parsing, pandas._libs.tslibs.conversion, pandas._libs.tslibs.period, pandas._libs.tslibs.vectorized, pandas._libs.ops_dispatch, pandas._libs.missing, pandas._libs.hashtable, pandas._libs.algos, pandas._libs.interval, pandas._libs.lib, pyarrow._compute, pandas._libs.ops, pandas._libs.hashing, pandas._libs.arrays, psutil._psutil_linux, psutil._psutil_posix, pandas._libs.tslib, pandas._libs.sparse, pandas._libs.internals, pandas._libs.indexing, pandas._libs.index, pandas._libs.writers, pandas._libs.join, _pydevd_bundle.pydevd_cython, pandas._libs.window.aggregations, pandas._libs.window.indexers, pandas._libs.reshape, pandas._libs.groupby, pandas._libs.json, pandas._libs.parsers, pandas._libs.testing, numpy._core._multiarray_umath, numpy._core._multiarray_tests, numpy.linalg._umath_linalg, pyarrow._parquet, pyarrow._fs, pyarrow._azurefs, pyarrow._hdfs, pyarrow._gcsfs, pyarrow._s3fs, multidict._multidict, torch._C, torch._C._dynamo.autograd_compiler, , torch._C._dynamo.eval_frameyarl._quoting_c, torch._C._dynamo.guards, , torch._C._dynamo.utilspropcache._helpers_c, torch._C._fft, torch._C._linalg, torch._C._nested, torch._C._nn, aiohttp._http_writer, torch._C._sparse, torch._C._special, aiohttp._http_parser, aiohttp._websocket.mask, aiohttp._websocket.reader_c, frozenlist._frozenlist, xxhash._xxhash, pyarrow._json, pyarrow._acero, pyarrow._csv, pyarrow._dataset, pyarrow._dataset_orc, pyarrow._parquet_encryption, pyarrow._dataset_parquet_encryption, pyarrow._dataset_parquet, markupsafe._speedups, sentencepiece._sentencepiece, PIL._imaging, PIL._imagingft, cuda_utils, __triton_launcher (total: 104)\n",
            ", numpy.random._common, numpy.random.bit_generator, numpy.random._bounded_integers, numpy.random._mt19937, numpy.random.mtrand, numpy.random._philox, numpy.random._pcg64, numpy.random._sfc64, numpy.random._generator, kiwisolver._cext, charset_normalizer.md, requests.packages.charset_normalizer.md, requests.packages.chardet.md, yaml._yaml, pyarrow.lib, pandas._libs.tslibs.ccalendar, pandas._libs.tslibs.np_datetime, pandas._libs.tslibs.dtypes, pandas._libs.tslibs.base, pandas._libs.tslibs.nattype, pandas._libs.tslibs.timezones, pandas._libs.tslibs.fields, pandas._libs.tslibs.timedeltas, pandas._libs.tslibs.tzconversion, pandas._libs.tslibs.timestamps, pandas._libs.properties, pandas._libs.tslibs.offsets, pandas._libs.tslibs.strptime, pandas._libs.tslibs.parsing, pandas._libs.tslibs.conversion, pandas._libs.tslibs.period, pandas._libs.tslibs.vectorized, pandas._libs.ops_dispatch, pandas._libs.missing, pandas._libs.hashtable, pandas._libs.algos, pandas._libs.interval, pandas._libs.lib, pyarrow._compute, pandas._libs.ops, pandas._libs.hashing, pandas._libs.arrays, pandas._libs.tslib, pandas._libs.sparse, pandas._libs.internals, pandas._libs.indexing, pandas._libs.index, pandas._libs.writers, pandas._libs.join, pandas._libs.window.aggregations, pandas._libs.window.indexers, pandas._libs.reshape, pandas._libs.groupby, pandas._libs.json, pandas._libs.parsers, pandas._libs.testing, pyarrow._parquet, pyarrow._fs, pyarrow._azurefs, pyarrow._hdfs, pyarrow._gcsfs, pyarrow._s3fs, multidict._multidict, yarl._quoting_c, propcache._helpers_c, aiohttp._http_writer, aiohttp._http_parser, aiohttp._websocket.mask, aiohttp._websocket.reader_c, frozenlist._frozenlist, xxhash._xxhash, pyarrow._json, pyarrow._acero, pyarrow._csv, pyarrow._dataset, pyarrow._dataset_orc, pyarrow._parquet_encryption, pyarrow._dataset_parquet_encryption, pyarrow._dataset_parquet, markupsafe._speedups, sentencepiece._sentencepiece, cuda_utils, __triton_launcher (total: 104)\n",
            "Fatal Python error: Segmentation fault\n",
            "\n",
            "Thread 0x0000151878448640 (most recent call first):\n",
            "  <no Python frame>\n",
            "\n",
            "Thread 0x0000151878247640 (most recent call first):\n",
            "  <no Python frame>\n",
            "\n",
            "Thread 0x0000151878649640 (most recent call first):\n",
            "  <no Python frame>\n",
            "\n",
            "Thread 0x00001517e0be5640 (most recent call first):\n",
            "  <no Python frame>\n",
            "\n",
            "Thread 0x000015187884a640 (most recent call first):\n",
            "  <no Python frame>\n",
            "\n",
            "Thread 0x00001517e05e2640 (most recent call first):\n",
            "  <no Python frame>\n",
            "\n",
            "Thread 0x00001517e09e4640 (most recent call first):\n",
            "  <no Python frame>\n",
            "\n",
            "Thread 0x00001517e07e3640 (most recent call first):\n",
            "  <no Python frame>\n",
            "\n",
            "Thread 0x00001517e03e1640 (most recent call first):\n",
            "  File \"/usr/lib/python3.10/threading.py\", line 324 in wait\n",
            "  File \"/usr/lib/python3.10/threading.py\", line 607 in wait\n",
            "  File \"/home/alex-zhao/.venv/lib/python3.10/site-packages/tqdm/_monitor.py\", line 60 in run\n",
            "  File \"/usr/lib/python3.10/threading.py\", line 1016 in _bootstrap_inner\n",
            "  File \"/usr/lib/python3.10/threading.py\", line 973 in _bootstrap\n",
            "\n",
            "Thread 0x00001517dbfff640 (most recent call first):\n",
            "  File \"/usr/lib/python3.10/threading.py\", line 324 in wait\n",
            "  File \"/usr/lib/python3.10/threading.py\", line 607 in wait\n",
            "  File \"/home/alex-zhao/.venv/lib/python3.10/site-packages/tqdm/_monitor.py\", line 60 in run\n",
            "  File \"/usr/lib/python3.10/threading.py\", line 1016 in _bootstrap_inner\n",
            "  File \"/usr/lib/python3.10/threading.py\", line 973 in _bootstrap\n",
            "\n",
            "Thread 0x00001517da9f4640 (most recent call first):\n",
            "  File \"/home/alex-zhao/.venv/lib/python3.10/site-packages/torch/_inductor/compile_worker/subproc_pool.py\", line 47 in _recv_msg\n",
            "  File \"/home/alex-zhao/.venv/lib/python3.10/site-packages/torch/_inductor/compile_worker/subproc_pool.py\", line 153 in _read_thread\n",
            "  File \"/usr/lib/python3.10/threading.py\", line 953 in run\n",
            "  File \"/home/alex-zhao/.venv/lib/python3.10/site-packages/ipykernel/ipkernel.py\", line 766 in run_closure\n",
            "  File \"/usr/lib/python3.10/threading.py\", line 1016 in _bootstrap_inner\n",
            "  File \"/usr/lib/python3.10/threading.py\", line 973 in _bootstrap\n",
            "\n",
            "Current thread 0x0000151996ed21c0 (most recent call first):\n",
            "  File \"/tmp/ipykernel_1160500/4248888456.py\", line 19 in torch_dynamo_resume_in_forward_at_16\n",
            "  File \"/tmp/ipykernel_1160500/4248888456.py\", line 14 in torch_dynamo_resume_in_forward_at_14\n",
            "  File \"/tmp/ipykernel_1160500/4248888456.py\", line 13 in forward\n",
            "  File \"/home/alex-zhao/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1747 in _call_impl\n",
            "  File \"/home/alex-zhao/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1736 in _wrapped_call_impl\n",
            "  File \"/tmp/ipykernel_1160500/161130724.py\", line 26 in torch_dynamo_resume_in_forward_at_20\n",
            "  File \"/tmp/ipykernel_1160500/161130724.py\", line 20 in torch_dynamo_resume_in_forward_at_20\n",
            "  File \"/tmp/ipykernel_1160500/161130724.py\", line 12 in forward\n",
            "  File \"/home/alex-zhao/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1747 in _call_impl\n",
            "  File \"/home/alex-zhao/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1736 in _wrapped_call_impl\n",
            "  File \"/home/alex-zhao/.venv/lib/python3.10/site-packages/torch/nn/parallel/distributed.py\", line 1459 in _run_ddp_forward\n",
            "  File \"/home/alex-zhao/.venv/lib/python3.10/site-packages/torch/nn/parallel/distributed.py\", line 1643 in forward\n",
            "  File \"/home/alex-zhao/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1747 in _call_impl\n",
            "  File \"/home/alex-zhao/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1736 in _wrapped_call_impl\n",
            "  File \"/home/alex-zhao/.venv/lib/python3.10/site-packages/torch/_dynamo/external_utils.py\", line 40 in inner\n",
            "  File \"/home/alex-zhao/.venv/lib/python3.10/site-packages/torch/_dynamo/eval_frame.py\", line 465 in _fn\n",
            "  File \"/tmp/ipykernel_1160500/3913905366.py\", line 54 in training_function\n",
            "  File \"/home/alex-zhao/.venv/lib/python3.10/site-packages/torch/distributed/elastic/multiprocessing/errors/__init__.py\", line 355 in wrapper\n",
            "  File \"/home/alex-zhao/.venv/lib/python3.10/site-packages/torch/distributed/elastic/multiprocessing/api.py\", line 611 in _wrap\n",
            "  File \"/home/alex-zhao/.venv/lib/python3.10/site-packages/torch/multiprocessing/spawn.py\", line 90 in _wrap\n",
            "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 108 in run\n",
            "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 314 in _bootstrap\n",
            "  File \"/usr/lib/python3.10/multiprocessing/popen_fork.py\", line 71 in _launch\n",
            "  File \"/usr/lib/python3.10/multiprocessing/popen_fork.py\", line 19 in __init__\n",
            "  File \"/usr/lib/python3.10/multiprocessing/context.py\", line 281 in _Popen\n",
            "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 121 in start\n",
            "  File \"/home/alex-zhao/.venv/lib/python3.10/site-packages/torch/multiprocessing/spawn.py\", line 263 in start_process\n",
            "  File \"/home/alex-zhao/.venv/lib/python3.10/site-packages/torch/multiprocessing/spawn.py\", line 268 in start_processes\n",
            "  File \"/home/alex-zhao/.venv/lib/python3.10/site-packages/torch/distributed/elastic/multiprocessing/api.py\", line 658 in _start\n",
            "  File \"/home/alex-zhao/.venv/lib/python3.10/site-packages/torch/distributed/elastic/multiprocessing/api.py\", line 485 in start\n",
            "  File \"/home/alex-zhao/.venv/lib/python3.10/site-packages/torch/distributed/elastic/multiprocessing/__init__.py\", line 229 in start_processes\n",
            "  File \"/home/alex-zhao/.venv/lib/python3.10/site-packages/torch/distributed/elastic/agent/server/local_elastic_agent.py\", line 343 in _start_workers\n",
            "  File \"/home/alex-zhao/.venv/lib/python3.10/site-packages/torch/distributed/elastic/metrics/api.py\", line 137 in wrapper\n",
            "  File \"/home/alex-zhao/.venv/lib/python3.10/site-packages/torch/distributed/elastic/agent/server/api.py\", line 671 in _initialize_workers\n",
            "  File \"/home/alex-zhao/.venv/lib/python3.10/site-packages/torch/distributed/elastic/metrics/api.py\", line 137 in wrapper\n",
            "  File \"/home/alex-zhao/.venv/lib/python3.10/site-packages/torch/distributed/elastic/agent/server/api.py\", line 849 in _invoke_run\n",
            "  File \"/home/alex-zhao/.venv/lib/python3.10/site-packages/torch/distributed/elastic/agent/server/api.py\", line 696 in run\n",
            "  File \"/home/alex-zhao/.venv/lib/python3.10/site-packages/torch/distributed/elastic/metrics/api.py\", line 137 in wrapper\n",
            "  File \"/home/alex-zhao/.venv/lib/python3.10/site-packages/torch/distributed/launcher/api.py\", line 260 in launch_agent\n",
            "  File \"/home/alex-zhao/.venv/lib/python3.10/site-packages/torch/distributed/launcher/api.py\", line 138 in __call__\n",
            "  File \"/home/alex-zhao/.venv/lib/python3.10/site-packages/accelerate/launchers.py\", line 245 in notebook_launcher\n",
            "  File \"/tmp/ipykernel_1160500/4060614896.py\", line 1 in <module>\n",
            "  File \"/home/alex-zhao/.venv/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3577 in run_code\n",
            "  File \"/home/alex-zhao/.venv/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3517 in run_ast_nodes\n",
            "  File \"/home/alex-zhao/.venv/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3334 in run_cell_async\n",
            "  File \"/home/alex-zhao/.venv/lib/python3.10/site-packages/IPython/core/async_helpers.py\", line 128 in _pseudo_sync_runner\n",
            "  File \"/home/alex-zhao/.venv/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3130 in _run_cell\n",
            "  File \"/home/alex-zhao/.venv/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3075 in run_cell\n",
            "  File \"/home/alex-zhao/.venv/lib/python3.10/site-packages/ipykernel/zmqshell.py\", line 549 in run_cell\n",
            "  File \"/home/alex-zhao/.venv/lib/python3.10/site-packages/ipykernel/ipkernel.py\", line 449 in do_execute\n",
            "  File \"/home/alex-zhao/.venv/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 778 in execute_request\n",
            "  File \"/home/alex-zhao/.venv/lib/python3.10/site-packages/ipykernel/ipkernel.py\", line 362 in execute_request\n",
            "  File \"/home/alex-zhao/.venv/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 437 in dispatch_shell\n",
            "  File \"/home/alex-zhao/.venv/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 534 in process_one\n",
            "  File \"/home/alex-zhao/.venv/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 545 in dispatch_queue\n",
            "  File \"/usr/lib/python3.10/asyncio/events.py\", line 80 in _run\n",
            "  File \"/usr/lib/python3.10/asyncio/base_events.py\", line 1909 in _run_once\n",
            "  File \"/usr/lib/python3.10/asyncio/base_events.py\", line 603 in run_forever\n",
            "  File \"/home/alex-zhao/.venv/lib/python3.10/site-packages/tornado/platform/asyncio.py\", line 205 in start\n",
            "  File \"/home/alex-zhao/.venv/lib/python3.10/site-packages/ipykernel/kernelapp.py\", line 739 in start\n",
            "  File \"/home/alex-zhao/.venv/lib/python3.10/site-packages/traitlets/config/application.py\", line 1075 in launch_instance\n",
            "  File \"/home/alex-zhao/.venv/lib/python3.10/site-packages/ipykernel_launcher.py\", line 18 in <module>\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 86 in _run_code\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 196 in _run_module_as_main\n",
            "\n",
            "Extension modules: zmq.backend.cython._zmq, tornado.speedups, psutil._psutil_linux, psutil._psutil_posix, _pydevd_bundle.pydevd_cython, numpy._core._multiarray_umath, numpy._core._multiarray_tests, numpy.linalg._umath_linalg, torch._C, torch._C._dynamo.autograd_compiler, torch._C._dynamo.eval_frame, torch._C._dynamo.guards, torch._C._dynamo.utils, torch._C._fft, torch._C._linalg, torch._C._nested, torch._C._nn, torch._C._sparse, torch._C._special, PIL._imaging, PIL._imagingft, numpy.random._common, numpy.random.bit_generator, numpy.random._bounded_integers, numpy.random._mt19937, numpy.random.mtrand, numpy.random._philox, numpy.random._pcg64, numpy.random._sfc64, numpy.random._generator, kiwisolver._cext, charset_normalizer.md, requests.packages.charset_normalizer.md, requests.packages.chardet.md, yaml._yaml, pyarrow.lib, pandas._libs.tslibs.ccalendar, pandas._libs.tslibs.np_datetime, pandas._libs.tslibs.dtypes, pandas._libs.tslibs.base, pandas._libs.tslibs.nattype, pandas._libs.tslibs.timezones, pandas._libs.tslibs.fields, pandas._libs.tslibs.timedeltas, pandas._libs.tslibs.tzconversion, pandas._libs.tslibs.timestamps, pandas._libs.properties, pandas._libs.tslibs.offsets, pandas._libs.tslibs.strptime, pandas._libs.tslibs.parsing, pandas._libs.tslibs.conversion, pandas._libs.tslibs.period, pandas._libs.tslibs.vectorized, pandas._libs.ops_dispatch, pandas._libs.missing, pandas._libs.hashtable, pandas._libs.algos, pandas._libs.interval, pandas._libs.lib, pyarrow._compute, pandas._libs.ops, pandas._libs.hashing, pandas._libs.arrays, pandas._libs.tslib, pandas._libs.sparse, pandas._libs.internals, pandas._libs.indexing, pandas._libs.index, pandas._libs.writers, pandas._libs.join, pandas._libs.window.aggregations, pandas._libs.window.indexers, pandas._libs.reshape, pandas._libs.groupby, pandas._libs.json, pandas._libs.parsers, pandas._libs.testing, pyarrow._parquet, pyarrow._fs, pyarrow._azurefs, pyarrow._hdfs, pyarrow._gcsfs, pyarrow._s3fs, multidict._multidict, yarl._quoting_c, propcache._helpers_c, aiohttp._http_writer, aiohttp._http_parser, aiohttp._websocket.mask, aiohttp._websocket.reader_c, frozenlist._frozenlist, xxhash._xxhash, pyarrow._json, pyarrow._acero, pyarrow._csv, pyarrow._dataset, pyarrow._dataset_orc, pyarrow._parquet_encryption, pyarrow._dataset_parquet_encryption, pyarrow._dataset_parquet, markupsafe._speedups, sentencepiece._sentencepiece, cuda_utils, __triton_launcher (total: 104)\n",
            "Fatal Python error: Segmentation fault\n",
            "\n",
            "Thread 0x00001517e11e8640 (most recent call first):\n",
            "  <no Python frame>\n",
            "\n",
            "Thread 0x00001517e0fe7640 (most recent call first):\n",
            "  <no Python frame>\n",
            "\n",
            "Thread 0x00001517e0de6640 (most recent call first):\n",
            "  <no Python frame>\n",
            "\n",
            "Thread 0x00001517e0be5640 (most recent call first):\n",
            "  <no Python frame>\n",
            "\n",
            "Thread 0x00001517e09e4640 (most recent call first):\n",
            "  <no Python frame>\n",
            "\n",
            "Thread 0x00001517e07e3640 (most recent call first):\n",
            "  <no Python frame>\n",
            "\n",
            "Thread 0x00001517e05e2640 (most recent call first):\n",
            "  <no Python frame>\n",
            "\n",
            "Thread 0x00001517e03e1640 (most recent call first):\n",
            "  <no Python frame>\n",
            "\n",
            "Thread 0x00001517dbfff640 (most recent call first):\n",
            "  File \"/usr/lib/python3.10/threading.py\", line 324 in wait\n",
            "  File \"/usr/lib/python3.10/threading.py\", line 607 in wait\n",
            "  File \"/home/alex-zhao/.venv/lib/python3.10/site-packages/tqdm/_monitor.py\", line 60 in run\n",
            "  File \"/usr/lib/python3.10/threading.py\", line 1016 in _bootstrap_inner\n",
            "  File \"/usr/lib/python3.10/threading.py\", line 973 in _bootstrap\n",
            "\n",
            "Thread 0x00001517da7f3640 (most recent call first):\n",
            "  File \"/home/alex-zhao/.venv/lib/python3.10/site-packages/torch/_inductor/compile_worker/subproc_pool.py\", line 47 in _recv_msg\n",
            "  File \"/home/alex-zhao/.venv/lib/python3.10/site-packages/torch/_inductor/compile_worker/subproc_pool.py\", line 153 in _read_thread\n",
            "  File \"/usr/lib/python3.10/threading.py\", line 953 in run\n",
            "  File \"/home/alex-zhao/.venv/lib/python3.10/site-packages/ipykernel/ipkernel.py\", line 766 in run_closure\n",
            "  File \"/usr/lib/python3.10/threading.py\", line 1016 in _bootstrap_inner\n",
            "  File \"/usr/lib/python3.10/threading.py\", line 973 in _bootstrap\n",
            "\n",
            "Current thread 0x0000151996ed21c0 (most recent call first):\n",
            "  File \"/tmp/ipykernel_1160500/4248888456.py\", line 19 in torch_dynamo_resume_in_forward_at_16\n",
            "  File \"/tmp/ipykernel_1160500/4248888456.py\", line 14 in torch_dynamo_resume_in_forward_at_14\n",
            "  File \"/tmp/ipykernel_1160500/4248888456.py\", line 13 in forward\n",
            "  File \"/home/alex-zhao/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1747 in _call_impl\n",
            "  File \"/home/alex-zhao/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1736 in _wrapped_call_impl\n",
            "  File \"/tmp/ipykernel_1160500/161130724.py\", line 26 in torch_dynamo_resume_in_forward_at_20\n",
            "  File \"/tmp/ipykernel_1160500/161130724.py\", line 20 in torch_dynamo_resume_in_forward_at_20\n",
            "  File \"/tmp/ipykernel_1160500/161130724.py\", line 12 in forward\n",
            "  File \"/home/alex-zhao/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1747 in _call_impl\n",
            "  File \"/home/alex-zhao/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1736 in _wrapped_call_impl\n",
            "  File \"/home/alex-zhao/.venv/lib/python3.10/site-packages/torch/nn/parallel/distributed.py\", line 1459 in _run_ddp_forward\n",
            "  File \"/home/alex-zhao/.venv/lib/python3.10/site-packages/torch/nn/parallel/distributed.py\", line 1643 in forward\n",
            "  File \"/home/alex-zhao/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1747 in _call_impl\n",
            "  File \"/home/alex-zhao/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1736 in _wrapped_call_impl\n",
            "  File \"/home/alex-zhao/.venv/lib/python3.10/site-packages/torch/_dynamo/external_utils.py\", line 40 in inner\n",
            "  File \"/home/alex-zhao/.venv/lib/python3.10/site-packages/torch/_dynamo/eval_frame.py\", line 465 in _fn\n",
            "  File \"/tmp/ipykernel_1160500/3913905366.py\", line 54 in training_function\n",
            "  File \"/home/alex-zhao/.venv/lib/python3.10/site-packages/torch/distributed/elastic/multiprocessing/errors/__init__.py\", line 355 in wrapper\n",
            "  File \"/home/alex-zhao/.venv/lib/python3.10/site-packages/torch/distributed/elastic/multiprocessing/api.py\", line 611 in _wrap\n",
            "  File \"/home/alex-zhao/.venv/lib/python3.10/site-packages/torch/multiprocessing/spawn.py\", line 90 in _wrap\n",
            "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 108 in run\n",
            "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 314 in _bootstrap\n",
            "  File \"/usr/lib/python3.10/multiprocessing/popen_fork.py\", line 71 in _launch\n",
            "  File \"/usr/lib/python3.10/multiprocessing/popen_fork.py\", line 19 in __init__\n",
            "  File \"/usr/lib/python3.10/multiprocessing/context.py\", line 281 in _Popen\n",
            "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 121 in start\n",
            "  File \"/home/alex-zhao/.venv/lib/python3.10/site-packages/torch/multiprocessing/spawn.py\", line 263 in start_process\n",
            "  File \"/home/alex-zhao/.venv/lib/python3.10/site-packages/torch/multiprocessing/spawn.py\", line 268 in start_processes\n",
            "  File \"/home/alex-zhao/.venv/lib/python3.10/site-packages/torch/distributed/elastic/multiprocessing/api.py\", line 658 in _start\n",
            "  File \"/home/alex-zhao/.venv/lib/python3.10/site-packages/torch/distributed/elastic/multiprocessing/api.py\", line 485 in start\n",
            "  File \"/home/alex-zhao/.venv/lib/python3.10/site-packages/torch/distributed/elastic/multiprocessing/__init__.py\", line 229 in start_processes\n",
            "  File \"/home/alex-zhao/.venv/lib/python3.10/site-packages/torch/distributed/elastic/agent/server/local_elastic_agent.py\", line 343 in _start_workers\n",
            "  File \"/home/alex-zhao/.venv/lib/python3.10/site-packages/torch/distributed/elastic/metrics/api.py\", line 137 in wrapper\n",
            "  File \"/home/alex-zhao/.venv/lib/python3.10/site-packages/torch/distributed/elastic/agent/server/api.py\", line 671 in _initialize_workers\n",
            "  File \"/home/alex-zhao/.venv/lib/python3.10/site-packages/torch/distributed/elastic/metrics/api.py\", line 137 in wrapper\n",
            "  File \"/home/alex-zhao/.venv/lib/python3.10/site-packages/torch/distributed/elastic/agent/server/api.py\", line 849 in _invoke_run\n",
            "  File \"/home/alex-zhao/.venv/lib/python3.10/site-packages/torch/distributed/elastic/agent/server/api.py\", line 696 in run\n",
            "  File \"/home/alex-zhao/.venv/lib/python3.10/site-packages/torch/distributed/elastic/metrics/api.py\", line 137 in wrapper\n",
            "  File \"/home/alex-zhao/.venv/lib/python3.10/site-packages/torch/distributed/launcher/api.py\", line 260 in launch_agent\n",
            "  File \"/home/alex-zhao/.venv/lib/python3.10/site-packages/torch/distributed/launcher/api.py\", line 138 in __call__\n",
            "  File \"/home/alex-zhao/.venv/lib/python3.10/site-packages/accelerate/launchers.py\", line 245 in notebook_launcher\n",
            "  File \"/tmp/ipykernel_1160500/4060614896.py\", line 1 in <module>\n",
            "  File \"/home/alex-zhao/.venv/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3577 in run_code\n",
            "  File \"/home/alex-zhao/.venv/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3517 in run_ast_nodes\n",
            "  File \"/home/alex-zhao/.venv/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3334 in run_cell_async\n",
            "  File \"/home/alex-zhao/.venv/lib/python3.10/site-packages/IPython/core/async_helpers.py\", line 128 in _pseudo_sync_runner\n",
            "  File \"/home/alex-zhao/.venv/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3130 in _run_cell\n",
            "  File \"/home/alex-zhao/.venv/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3075 in run_cell\n",
            "  File \"/home/alex-zhao/.venv/lib/python3.10/site-packages/ipykernel/zmqshell.py\", line 549 in run_cell\n",
            "  File \"/home/alex-zhao/.venv/lib/python3.10/site-packages/ipykernel/ipkernel.py\", line 449 in do_execute\n",
            "  File \"/home/alex-zhao/.venv/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 778 in execute_request\n",
            "  File \"/home/alex-zhao/.venv/lib/python3.10/site-packages/ipykernel/ipkernel.py\", line 362 in execute_request\n",
            "  File \"/home/alex-zhao/.venv/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 437 in dispatch_shell\n",
            "  File \"/home/alex-zhao/.venv/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 534 in process_one\n",
            "  File \"/home/alex-zhao/.venv/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 545 in dispatch_queue\n",
            "  File \"/usr/lib/python3.10/asyncio/events.py\", line 80 in _run\n",
            "  File \"/usr/lib/python3.10/asyncio/base_events.py\", line 1909 in _run_once\n",
            "  File \"/usr/lib/python3.10/asyncio/base_events.py\", line 603 in run_forever\n",
            "  File \"/home/alex-zhao/.venv/lib/python3.10/site-packages/tornado/platform/asyncio.py\", line 205 in start\n",
            "  File \"/home/alex-zhao/.venv/lib/python3.10/site-packages/ipykernel/kernelapp.py\", line 739 in start\n",
            "  File \"/home/alex-zhao/.venv/lib/python3.10/site-packages/traitlets/config/application.py\", line 1075 in launch_instance\n",
            "  File \"/home/alex-zhao/.venv/lib/python3.10/site-packages/ipykernel_launcher.py\", line 18 in <module>\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 86 in _run_code\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 196 in _run_module_as_main\n",
            "\n",
            "Extension modules: zmq.backend.cython._zmq, tornado.speedups, psutil._psutil_linux, psutil._psutil_posix, _pydevd_bundle.pydevd_cython, numpy._core._multiarray_umath, numpy._core._multiarray_tests, numpy.linalg._umath_linalg, torch._C, torch._C._dynamo.autograd_compiler, torch._C._dynamo.eval_frame, torch._C._dynamo.guards, torch._C._dynamo.utils, torch._C._fft, torch._C._linalg, torch._C._nested, torch._C._nn, torch._C._sparse, torch._C._special, PIL._imaging, PIL._imagingft, numpy.random._common, numpy.random.bit_generator, numpy.random._bounded_integers, numpy.random._mt19937, numpy.random.mtrand, numpy.random._philox, numpy.random._pcg64, numpy.random._sfc64, numpy.random._generator, kiwisolver._cext, charset_normalizer.md, requests.packages.charset_normalizer.md, requests.packages.chardet.md, yaml._yaml, pyarrow.lib, pandas._libs.tslibs.ccalendar, pandas._libs.tslibs.np_datetime, pandas._libs.tslibs.dtypes, pandas._libs.tslibs.base, pandas._libs.tslibs.nattype, pandas._libs.tslibs.timezones, pandas._libs.tslibs.fields, pandas._libs.tslibs.timedeltas, pandas._libs.tslibs.tzconversion, pandas._libs.tslibs.timestamps, pandas._libs.properties, pandas._libs.tslibs.offsets, pandas._libs.tslibs.strptime, pandas._libs.tslibs.parsing, pandas._libs.tslibs.conversion, pandas._libs.tslibs.period, pandas._libs.tslibs.vectorized, pandas._libs.ops_dispatch, pandas._libs.missing, pandas._libs.hashtable, pandas._libs.algos, pandas._libs.interval, pandas._libs.lib, pyarrow._compute, pandas._libs.ops, pandas._libs.hashing, pandas._libs.arrays, pandas._libs.tslib, pandas._libs.sparse, pandas._libs.internals, pandas._libs.indexing, pandas._libs.index, pandas._libs.writers, pandas._libs.join, pandas._libs.window.aggregations, pandas._libs.window.indexers, pandas._libs.reshape, pandas._libs.groupby, pandas._libs.json, pandas._libs.parsers, pandas._libs.testing, pyarrow._parquet, pyarrow._fs, pyarrow._azurefs, pyarrow._hdfs, pyarrow._gcsfs, pyarrow._s3fs, multidict._multidict, yarl._quoting_c, propcache._helpers_c, aiohttp._http_writer, aiohttp._http_parser, aiohttp._websocket.mask, aiohttp._websocket.reader_c, frozenlist._frozenlist, xxhash._xxhash, pyarrow._json, pyarrow._acero, pyarrow._csv, pyarrow._dataset, pyarrow._dataset_orc, pyarrow._parquet_encryption, pyarrow._dataset_parquet_encryption, pyarrow._dataset_parquet, markupsafe._speedups, sentencepiece._sentencepiece, cuda_utils, __triton_launcher (total: 104)\n",
            "W1224 02:00:55.028000 1160500 torch/multiprocessing/spawn.py:160] Terminating process 1160849 via signal SIGTERM\n",
            "W1224 02:00:55.030000 1160500 torch/multiprocessing/spawn.py:160] Terminating process 1160851 via signal SIGTERM\n",
            "W1224 02:00:55.031000 1160500 torch/multiprocessing/spawn.py:160] Terminating process 1160853 via signal SIGTERM\n",
            "W1224 02:00:55.032000 1160500 torch/multiprocessing/spawn.py:160] Terminating process 1160855 via signal SIGTERM\n",
            "W1224 02:00:55.032000 1160500 torch/multiprocessing/spawn.py:160] Terminating process 1160857 via signal SIGTERM\n",
            "W1224 02:00:55.033000 1160500 torch/multiprocessing/spawn.py:160] Terminating process 1160859 via signal SIGTERM\n",
            "W1224 02:00:55.033000 1160500 torch/multiprocessing/spawn.py:160] Terminating process 1160861 via signal SIGTERM\n",
            "E1224 02:00:56.195000 1160500 torch/distributed/elastic/multiprocessing/api.py:732] failed (exitcode: -11) local_rank: 0 (pid: 1160847) of fn: training_function (start_method: fork)\n",
            "E1224 02:00:56.195000 1160500 torch/distributed/elastic/multiprocessing/api.py:732] Traceback (most recent call last):\n",
            "E1224 02:00:56.195000 1160500 torch/distributed/elastic/multiprocessing/api.py:732]   File \"/home/alex-zhao/.venv/lib/python3.10/site-packages/torch/distributed/elastic/multiprocessing/api.py\", line 687, in _poll\n",
            "E1224 02:00:56.195000 1160500 torch/distributed/elastic/multiprocessing/api.py:732]     self._pc.join(-1)\n",
            "E1224 02:00:56.195000 1160500 torch/distributed/elastic/multiprocessing/api.py:732]   File \"/home/alex-zhao/.venv/lib/python3.10/site-packages/torch/multiprocessing/spawn.py\", line 184, in join\n",
            "E1224 02:00:56.195000 1160500 torch/distributed/elastic/multiprocessing/api.py:732]     raise ProcessExitedException(\n",
            "E1224 02:00:56.195000 1160500 torch/distributed/elastic/multiprocessing/api.py:732] torch.multiprocessing.spawn.ProcessExitedException: process 0 terminated with signal SIGSEGV\n"
          ]
        },
        {
          "ename": "ChildFailedError",
          "evalue": "\n============================================================\ntraining_function FAILED\n------------------------------------------------------------\nFailures:\n  <NO_OTHER_FAILURES>\n------------------------------------------------------------\nRoot Cause (first observed failure):\n[0]:\n  time      : 2024-12-24_02:00:56\n  host      : worker-42.etched-slurm-worker-svc.etched-slurm.svc.cluster.local\n  rank      : 0 (local_rank: 0)\n  exitcode  : -11 (pid: 1160847)\n  error_file: <N/A>\n  traceback : Signal 11 (SIGSEGV) received by PID 1160847\n============================================================",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mChildFailedError\u001b[0m                          Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[23], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mnotebook_launcher\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtraining_function\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_processes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m8\u001b[39;49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m~/.venv/lib/python3.10/site-packages/accelerate/launchers.py:245\u001b[0m, in \u001b[0;36mnotebook_launcher\u001b[0;34m(function, args, num_processes, mixed_precision, use_port, master_addr, node_rank, num_nodes, rdzv_backend, rdzv_endpoint, rdzv_conf, rdzv_id, max_restarts, monitor_interval, log_line_prefix_template)\u001b[0m\n\u001b[1;32m    243\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m is_torch_version(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m>=\u001b[39m\u001b[38;5;124m\"\u001b[39m, ELASTIC_LOG_LINE_PREFIX_TEMPLATE_PYTORCH_VERSION):\n\u001b[1;32m    244\u001b[0m         launch_config_kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlog_line_prefix_template\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m log_line_prefix_template\n\u001b[0;32m--> 245\u001b[0m     \u001b[43melastic_launch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mLaunchConfig\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mlaunch_config_kwargs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mentrypoint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfunction\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    246\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m ProcessRaisedException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    247\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot re-initialize CUDA in forked subprocess\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m e\u001b[38;5;241m.\u001b[39margs[\u001b[38;5;241m0\u001b[39m]:\n",
            "File \u001b[0;32m~/.venv/lib/python3.10/site-packages/torch/distributed/launcher/api.py:138\u001b[0m, in \u001b[0;36melastic_launch.__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    137\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs):\n\u001b[0;32m--> 138\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mlaunch_agent\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_config\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_entrypoint\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m~/.venv/lib/python3.10/site-packages/torch/distributed/launcher/api.py:269\u001b[0m, in \u001b[0;36mlaunch_agent\u001b[0;34m(config, entrypoint, args)\u001b[0m\n\u001b[1;32m    262\u001b[0m     events\u001b[38;5;241m.\u001b[39mrecord(agent\u001b[38;5;241m.\u001b[39mget_event_succeeded())\n\u001b[1;32m    264\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m result\u001b[38;5;241m.\u001b[39mis_failed():\n\u001b[1;32m    265\u001b[0m         \u001b[38;5;66;03m# ChildFailedError is treated specially by @record\u001b[39;00m\n\u001b[1;32m    266\u001b[0m         \u001b[38;5;66;03m# if the error files for the failed children exist\u001b[39;00m\n\u001b[1;32m    267\u001b[0m         \u001b[38;5;66;03m# @record will copy the first error (root cause)\u001b[39;00m\n\u001b[1;32m    268\u001b[0m         \u001b[38;5;66;03m# to the error file of the launcher process.\u001b[39;00m\n\u001b[0;32m--> 269\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m ChildFailedError(\n\u001b[1;32m    270\u001b[0m             name\u001b[38;5;241m=\u001b[39mentrypoint_name,\n\u001b[1;32m    271\u001b[0m             failures\u001b[38;5;241m=\u001b[39mresult\u001b[38;5;241m.\u001b[39mfailures,\n\u001b[1;32m    272\u001b[0m         )\n\u001b[1;32m    274\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m result\u001b[38;5;241m.\u001b[39mreturn_values\n\u001b[1;32m    275\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m ChildFailedError:\n",
            "\u001b[0;31mChildFailedError\u001b[0m: \n============================================================\ntraining_function FAILED\n------------------------------------------------------------\nFailures:\n  <NO_OTHER_FAILURES>\n------------------------------------------------------------\nRoot Cause (first observed failure):\n[0]:\n  time      : 2024-12-24_02:00:56\n  host      : worker-42.etched-slurm-worker-svc.etched-slurm.svc.cluster.local\n  rank      : 0 (local_rank: 0)\n  exitcode  : -11 (pid: 1160847)\n  error_file: <N/A>\n  traceback : Signal 11 (SIGSEGV) received by PID 1160847\n============================================================"
          ]
        }
      ],
      "source": [
        "notebook_launcher(training_function, num_processes=8)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "id": "e54b35c5",
      "metadata": {},
      "outputs": [],
      "source": [
        "ds = load_dataset(\"nampdn-ai/tiny-textbooks\", cache_dir=\"/shared/alex-zhao-storage/hf-cache\")\n",
        "L = tokenizer.batch_encode_plus(ds['train']['textbook'][:100], padding=True, truncation=True, max_length=513, padding_side='left')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "id": "96a60f76",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Launching training on 8 GPUs.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
          ]
        }
      ],
      "source": [
        "L = tokenizer.batch_encode_plus(all_dialogues, padding=True, truncation=True, max_length=33, padding_side='left')\n",
        "dataloader = DataLoader(L['input_ids'], batch_size=8)\n",
        "tokens = tokenizer.batch_encode_plus(all_dialogues, padding=True, truncation=True, max_length=33, padding_side='left')\n",
        "notebook_launcher(training_function, args=(dataloader,), num_processes=8)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "757e5237",
      "metadata": {},
      "outputs": [],
      "source": [
        "# import torch\n",
        "# import torch.nn as nn\n",
        "# from torch.profiler import profile, record_function, ProfilerActivity\n",
        "# from torch.utils.data import DataLoader\n",
        "# from tqdm import tqdm\n",
        "# import torch.distributed\n",
        "# from accelerate import Accelerator, DistributedDataParallelKwargs\n",
        "\n",
        "# ddp_kwargs = DistributedDataParallelKwargs(find_unused_parameters=True)\n",
        "\n",
        "# def training_function():\n",
        "#     # Initialize Accelerator (with DDP if used)\n",
        "#     accelerator = Accelerator(kwargs_handlers=[ddp_kwargs])\n",
        "    \n",
        "#     model = MambaLM(\n",
        "#         tokenizer.vocab_size, \n",
        "#         n_layers=12,\n",
        "#         n_heads=12,\n",
        "#         d_model=768,\n",
        "#         d_state=128,\n",
        "#         d_conv=4,\n",
        "#         expand=2,\n",
        "#     )\n",
        "\n",
        "#     optimizer = torch.optim.AdamW(model.parameters(), lr=0.0001)\n",
        "#     scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=100)\n",
        "\n",
        "#     # Tokenize and create DataLoader\n",
        "#     L = tokenizer.batch_encode_plus(all_dialogues, padding=True, truncation=True, max_length=50, padding_side='left')\n",
        "#     ds = DataLoader(L['input_ids'], batch_size=12)\n",
        "\n",
        "#     num_batches = len(ds)\n",
        "#     model, ds, optimizer, scheduler = accelerator.prepare(model, ds, optimizer, scheduler)\n",
        "    \n",
        "#     epochs = 1\n",
        "#     ce = nn.CrossEntropyLoss()\n",
        "\n",
        "#     progress_bar = None\n",
        "#     if accelerator.is_main_process:\n",
        "#         progress_bar = tqdm(total=epochs * num_batches, desc=\"Training Progress\")\n",
        "    \n",
        "#     # ------------------------------\n",
        "#     # START PROFILER CONTEXT\n",
        "#     # ------------------------------\n",
        "#     with profile(\n",
        "#         activities=[ProfilerActivity.CPU, ProfilerActivity.CUDA],\n",
        "#         record_shapes=True,      # (optional) get input shapes\n",
        "#         with_stack=True,         # (optional) gather stack traces\n",
        "#         profile_memory=True      # (optional) track tensor memory usage\n",
        "#     ) as prof:\n",
        "\n",
        "#         for epoch in range(epochs):\n",
        "#             for index, batch in enumerate(ds):\n",
        "#                 # Limit to 5 batches for a quick profiling run\n",
        "#                 if index >= 1:\n",
        "#                     break\n",
        "\n",
        "#                 x = torch.stack(batch, dim=-1)\n",
        "                \n",
        "#                 optimizer.zero_grad()\n",
        "#                 with record_function(\"forward_pass\"):\n",
        "#                     out = model(x[:, :-1])  # model forward\n",
        "\n",
        "#                 with record_function(\"loss_calc\"):\n",
        "#                     loss = ce(out.transpose(1,2), x[:, 1:])\n",
        "                \n",
        "#                 with record_function(\"backward\"):\n",
        "#                     accelerator.backward(loss)\n",
        "                \n",
        "#                 with record_function(\"optimizer_step\"):\n",
        "#                     optimizer.step()\n",
        "#                     scheduler.step()\n",
        "\n",
        "#                 if accelerator.is_main_process:\n",
        "#                     progress_bar.update(1)\n",
        "\n",
        "#                 # Only call all_reduce if we're actually in a distributed context\n",
        "#                 if torch.distributed.is_initialized() and torch.distributed.get_world_size() > 1:\n",
        "#                     processed_batches = torch.tensor(1, device=accelerator.device)\n",
        "#                     torch.distributed.all_reduce(processed_batches, op=torch.distributed.ReduceOp.SUM)\n",
        "\n",
        "#                 print(f\"Loss: {loss.item():0.4f}\")\n",
        "#                 print(f\"Batch {index} complete\")\n",
        "#                 batch_sum = torch.sum(x.flatten()) % (10**7 + 9)\n",
        "#                 print(f\"Batch sum mod 10^7+9: {batch_sum.item()}\")\n",
        "\n",
        "#     # ------------------------------\n",
        "#     # END PROFILER CONTEXT\n",
        "#     # ------------------------------\n",
        "\n",
        "#     if accelerator.is_main_process:\n",
        "#         progress_bar.close()\n",
        "\n",
        "#     # Print a summary of the top CPU-consuming ops\n",
        "#     print(prof.key_averages().table(sort_by=\"cpu_time_total\", row_limit=30))\n",
        "\n",
        "#     # Save final model\n",
        "#     unwrapped_model = accelerator.unwrap_model(model)\n",
        "#     torch.save(unwrapped_model.state_dict(), \"my_fsdp_fp32_model.pt\")\n",
        "#     print(\"Model saved at my_fsdp_fp32_model.pt\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3019cd62",
      "metadata": {},
      "outputs": [],
      "source": [
        "from accelerate import notebook_launcher\n",
        "notebook_launcher(training_function, num_processes=8)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "30989bd8",
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"Model params\", num_params(model))\n",
        "print(\"Layer params\", num_params(model.layers[0]))\n",
        "print(\"Head params\", num_params(model.layers[0].Heads[0]))\n",
        "print(\"SSM params\", num_params(model.layers[0].Heads[0].ssm))\n",
        "print(\"Conv params\", num_params(model.layers[0].Heads[0].conv))\n",
        "print(\"Up params\", num_params(model.layers[0].Heads[0].upscale))\n",
        "print(\"Gate params\", num_params(model.layers[0].Heads[0].gate))\n",
        "print(\"Down params\", num_params(model.layers[0].Heads[0].downscale))\n",
        "print(\"RMS params\", num_params(model.layers[0].rms_norm))\n",
        "print(\"Out params\", num_params(model.layers[0].out_project))\n",
        "print(\"Layer norm params\", num_params(model.layers[0].layer_norm))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9d5d77ba",
      "metadata": {},
      "outputs": [],
      "source": [
        "torch.cuda.memory._record_memory_history(max_entries=100000)\n",
        "tokens = tokenizer.encode(\"hello there, happy world!\")\n",
        "tokens = torch.tensor(tokens).unsqueeze(0).to('cuda')\n",
        "tokens = torch.cat([torch.zeros(1, 5, device='cuda', dtype=tokens.dtype), tokens], dim=1)\n",
        "generation = model.forward(tokens)\n",
        "print(tokenizer.decode(generation[0].argmax(dim=-1).tolist()))\n",
        "\n",
        "torch.cuda.memory._dump_snapshot(\"snapshot.pickle\")\n",
        "torch.cuda.memory._record_memory_history(enabled=None)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "A100",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
