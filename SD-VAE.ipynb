{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import numpy as np\n",
    "from tqdm.notebook import tqdm, trange\n",
    "\n",
    "import os\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "from accelerate import Accelerator, notebook_launcher"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImageNetDataset(Dataset):\n",
    "    def __init__(self, root_dir, transform=None):\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "        self.image_paths = []\n",
    "        \n",
    "        # Recursively find all image files\n",
    "        for root, _, files in os.walk(root_dir):\n",
    "            for file in files:\n",
    "                if file.lower().endswith(('.png', '.jpg', '.jpeg')):\n",
    "                    self.image_paths.append(os.path.join(root, file))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = self.image_paths[idx]\n",
    "        image = Image.open(img_path).convert('RGB')\n",
    "        \n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "            \n",
    "        return image\n",
    "\n",
    "# Define transformations\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((256, 256)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], \n",
    "                       std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "# Create dataset and dataloader\n",
    "dataset = ImageNetDataset(root_dir='/shared/imagenet/train', \n",
    "                         transform=transform)\n",
    "dataloader = DataLoader(dataset, \n",
    "                       batch_size=2048,\n",
    "                       shuffle=True,\n",
    "                       num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "625"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 3, 224, 224])\n",
      "torch.Size([2048, 512])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import clip\n",
    "from PIL import Image\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "clip_model, preprocess = clip.load(\"ViT-B/32\", device=device)\n",
    "for param in clip_model.parameters():\n",
    "    param.requires_grad = False\n",
    "resize = transforms.Resize((224, 224))\n",
    "\n",
    "images = preprocess(Image.open('/shared/imagenet/train/image_0.jpg')).unsqueeze(0).to(device)\n",
    "print(images.shape)\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch in dataloader:\n",
    "        print(clip_model.encode_image(resize(batch).to(device)).shape)\n",
    "        break\n",
    "\n",
    "def viz_loss(truth_batch, output_batch):\n",
    "    truth_scores = clip_model.encode_image(resize(truth_batch).to(device))\n",
    "    output_scores = clip_model.encode_image(resize(output_batch).to(device))\n",
    "    return (truth_scores - output_scores).pow(2).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "SD-VAE\n",
    "\n",
    "Replicates f8c4p2 on 256x256 ImageNet, i.e. 256x256 -> 16x16x12.\n",
    "\n",
    "Conv structure:\n",
    "* \n",
    "\"\"\"\n",
    "\n",
    "def space_2_channel(x):\n",
    "    output = torch.cat((x[:, :, 0::2, 0::2] + x[:, :, 0::2, 1::2], x[:, :, 1::2, 0::2] + x[:, :, 1::2, 1::2]), dim=1) / 2\n",
    "    assert(output.shape == (x.shape[0], x.shape[1] * 2, x.shape[2] // 2, x.shape[3] // 2))\n",
    "    return output\n",
    "\n",
    "def channel_2_space(x):\n",
    "    output = torch.zeros((x.shape[0], x.shape[1] // 2, x.shape[2] * 2, x.shape[3] * 2), device=x.device)\n",
    "    half_C = x.shape[1] // 2\n",
    "    output[:, :, ::2, ::2] = x[:, :half_C, :, :]\n",
    "    output[:, :, ::2, 1::2] = x[:, half_C:, :, :]\n",
    "    output[:, :, 1::2, ::2] = x[:, half_C:, :, :]\n",
    "    output[:, :, 1::2, 1::2] = x[:, :half_C, :, :]\n",
    "    return output\n",
    "\n",
    "kernel_sizes = [11, 9, 5, 3, 3]\n",
    "strides = [2, 2, 2, 2, 2]\n",
    "paddings = [k//2 for k in kernel_sizes]\n",
    "\n",
    "class SANA_Encoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.layers = nn.ModuleList([nn.Conv2d(3 * 2**index, 6 * 2**index, kernel_size, strides[index], paddings[index]) for index, kernel_size in enumerate(kernel_sizes)])\n",
    "        self.activation = nn.LeakyReLU(0.2)\n",
    "        self.norms = nn.ModuleList([nn.LayerNorm(\n",
    "            (\n",
    "                int(3 * 2**(index+1)),\n",
    "                int(256 / 2**(index+1)),\n",
    "                int(256 / 2**(index+1))\n",
    "            )\n",
    "        ) for index in range(len(kernel_sizes))])\n",
    "\n",
    "    def forward(self, x):\n",
    "        for layer, norm in zip(self.layers, self.norms):\n",
    "            x = layer(x) + space_2_channel(x)\n",
    "            x = self.activation(x)\n",
    "            x = norm(x)\n",
    "        return x\n",
    "\n",
    "class SANA_Decoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.layers = nn.ModuleList([nn.ConvTranspose2d(6 * 2**index, 3 * 2**index, kernel_size, strides[index], paddings[index], output_padding=strides[index]-1) for index, kernel_size in enumerate(kernel_sizes)][::-1])\n",
    "        self.activation = nn.LeakyReLU(0.2)\n",
    "        self.norms = nn.ModuleList([nn.LayerNorm(\n",
    "            (\n",
    "                int(3 * 2**index),\n",
    "                int(256 / 2**index),\n",
    "                int(256 / 2**index)\n",
    "            )\n",
    "        ) for index in range(len(kernel_sizes))][::-1])\n",
    "\n",
    "    def forward(self, x):\n",
    "        for layer, norm in zip(self.layers, self.norms):\n",
    "            x = layer(x) + channel_2_space(x)\n",
    "            x = self.activation(x)\n",
    "            x = norm(x)\n",
    "        return x\n",
    "\n",
    "class SANA_VAE(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.encoder = SANA_Encoder()\n",
    "        self.decoder = SANA_Decoder()\n",
    "\n",
    "    def encode(self, x):\n",
    "        return self.encoder(x)\n",
    "\n",
    "    def decode(self, x):\n",
    "        return self.decoder(x)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.decode(self.encode(x))\n",
    "\n",
    "    def train(self, dataloader, optimizer, epochs=100):\n",
    "        best_loss = float('inf')\n",
    "        for _ in trange(epochs, desc=\"Epochs\", leave=True):\n",
    "            epoch_loss = 0\n",
    "            for batch in tqdm(dataloader, desc=\"Batches\", leave=True):\n",
    "                batch = batch.to(device)\n",
    "                optimizer.zero_grad()\n",
    "                output = self.forward(batch)\n",
    "                loss = viz_loss(batch, output)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                epoch_loss += loss.item()\n",
    "            print(f\"Loss: {epoch_loss / len(dataloader)}\")\n",
    "            if epoch_loss < best_loss:\n",
    "                best_loss = epoch_loss\n",
    "                torch.save(self.state_dict(), \"sana_vae.pt\")\n",
    "        print(f\"Best loss: {best_loss}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = SANA_VAE().to(device)\n",
    "def num_params(model):\n",
    "    return sum(p.numel() for p in model.parameters())\n",
    "# print(f\"Number of parameters: {num_params(model)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e29ba427ce3c492cb2b7140695af654c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epochs:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6b3f82e3c7bc4f758d668d2a8334c5e3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/625 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = SANA_VAE().to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "model.train(dataloader, optimizer, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def training_function():\n",
    "    accelerator = Accelerator()\n",
    "    model = SANA_VAE()\n",
    "    print(f\"Number of parameters: {num_params(model)}\")\n",
    "    dataloader = DataLoader(dataset, batch_size=2048, shuffle=True, num_workers=4)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "    model, optimizer, dataloader = accelerator.prepare(model, optimizer, dataloader)\n",
    "    for _ in trange(10, desc=\"Epochs\", leave=True):\n",
    "        for batch in tqdm(dataloader, desc=\"Batches\", leave=True):\n",
    "            optimizer.zero_grad()\n",
    "            output = model(batch)\n",
    "            loss = viz_loss(batch, output)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        print(f\"Loss: {loss.item()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Launching training on 8 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E1224 08:44:31.473000 199646 torch/distributed/elastic/multiprocessing/api.py:732] failed (exitcode: 1) local_rank: 0 (pid: 200201) of fn: training_function (start_method: fork)\n",
      "E1224 08:44:31.473000 199646 torch/distributed/elastic/multiprocessing/api.py:732] Traceback (most recent call last):\n",
      "E1224 08:44:31.473000 199646 torch/distributed/elastic/multiprocessing/api.py:732]   File \"/home/alex-zhao/.venv/lib/python3.10/site-packages/torch/distributed/elastic/multiprocessing/api.py\", line 687, in _poll\n",
      "E1224 08:44:31.473000 199646 torch/distributed/elastic/multiprocessing/api.py:732]     self._pc.join(-1)\n",
      "E1224 08:44:31.473000 199646 torch/distributed/elastic/multiprocessing/api.py:732]   File \"/home/alex-zhao/.venv/lib/python3.10/site-packages/torch/multiprocessing/spawn.py\", line 203, in join\n",
      "E1224 08:44:31.473000 199646 torch/distributed/elastic/multiprocessing/api.py:732]     raise ProcessRaisedException(msg, error_index, failed_process.pid)\n",
      "E1224 08:44:31.473000 199646 torch/distributed/elastic/multiprocessing/api.py:732] torch.multiprocessing.spawn.ProcessRaisedException: \n",
      "E1224 08:44:31.473000 199646 torch/distributed/elastic/multiprocessing/api.py:732] \n",
      "E1224 08:44:31.473000 199646 torch/distributed/elastic/multiprocessing/api.py:732] -- Process 0 terminated with the following error:\n",
      "E1224 08:44:31.473000 199646 torch/distributed/elastic/multiprocessing/api.py:732] Traceback (most recent call last):\n",
      "E1224 08:44:31.473000 199646 torch/distributed/elastic/multiprocessing/api.py:732]   File \"/home/alex-zhao/.venv/lib/python3.10/site-packages/torch/multiprocessing/spawn.py\", line 90, in _wrap\n",
      "E1224 08:44:31.473000 199646 torch/distributed/elastic/multiprocessing/api.py:732]     fn(i, *args)\n",
      "E1224 08:44:31.473000 199646 torch/distributed/elastic/multiprocessing/api.py:732]   File \"/home/alex-zhao/.venv/lib/python3.10/site-packages/torch/distributed/elastic/multiprocessing/api.py\", line 611, in _wrap\n",
      "E1224 08:44:31.473000 199646 torch/distributed/elastic/multiprocessing/api.py:732]     ret = record(fn)(*args_)\n",
      "E1224 08:44:31.473000 199646 torch/distributed/elastic/multiprocessing/api.py:732]   File \"/home/alex-zhao/.venv/lib/python3.10/site-packages/torch/distributed/elastic/multiprocessing/errors/__init__.py\", line 355, in wrapper\n",
      "E1224 08:44:31.473000 199646 torch/distributed/elastic/multiprocessing/api.py:732]     return f(*args, **kwargs)\n",
      "E1224 08:44:31.473000 199646 torch/distributed/elastic/multiprocessing/api.py:732]   File \"/tmp/ipykernel_199646/2341702742.py\", line 2, in training_function\n",
      "E1224 08:44:31.473000 199646 torch/distributed/elastic/multiprocessing/api.py:732]     accelerator = Accelerator()\n",
      "E1224 08:44:31.473000 199646 torch/distributed/elastic/multiprocessing/api.py:732]   File \"/home/alex-zhao/.venv/lib/python3.10/site-packages/accelerate/accelerator.py\", line 425, in __init__\n",
      "E1224 08:44:31.473000 199646 torch/distributed/elastic/multiprocessing/api.py:732]     self.state = AcceleratorState(\n",
      "E1224 08:44:31.473000 199646 torch/distributed/elastic/multiprocessing/api.py:732]   File \"/home/alex-zhao/.venv/lib/python3.10/site-packages/accelerate/state.py\", line 861, in __init__\n",
      "E1224 08:44:31.473000 199646 torch/distributed/elastic/multiprocessing/api.py:732]     PartialState(cpu, **kwargs)\n",
      "E1224 08:44:31.473000 199646 torch/distributed/elastic/multiprocessing/api.py:732]   File \"/home/alex-zhao/.venv/lib/python3.10/site-packages/accelerate/state.py\", line 276, in __init__\n",
      "E1224 08:44:31.473000 199646 torch/distributed/elastic/multiprocessing/api.py:732]     self.set_device()\n",
      "E1224 08:44:31.473000 199646 torch/distributed/elastic/multiprocessing/api.py:732]   File \"/home/alex-zhao/.venv/lib/python3.10/site-packages/accelerate/state.py\", line 791, in set_device\n",
      "E1224 08:44:31.473000 199646 torch/distributed/elastic/multiprocessing/api.py:732]     device_module.set_device(self.device)\n",
      "E1224 08:44:31.473000 199646 torch/distributed/elastic/multiprocessing/api.py:732]   File \"/home/alex-zhao/.venv/lib/python3.10/site-packages/torch/cuda/__init__.py\", line 478, in set_device\n",
      "E1224 08:44:31.473000 199646 torch/distributed/elastic/multiprocessing/api.py:732]     torch._C._cuda_setDevice(device)\n",
      "E1224 08:44:31.473000 199646 torch/distributed/elastic/multiprocessing/api.py:732]   File \"/home/alex-zhao/.venv/lib/python3.10/site-packages/torch/cuda/__init__.py\", line 305, in _lazy_init\n",
      "E1224 08:44:31.473000 199646 torch/distributed/elastic/multiprocessing/api.py:732]     raise RuntimeError(\n",
      "E1224 08:44:31.473000 199646 torch/distributed/elastic/multiprocessing/api.py:732] RuntimeError: Cannot re-initialize CUDA in forked subprocess. To use CUDA with multiprocessing, you must use the 'spawn' start method\n",
      "E1224 08:44:31.473000 199646 torch/distributed/elastic/multiprocessing/api.py:732] \n"
     ]
    },
    {
     "ename": "ChildFailedError",
     "evalue": "\n============================================================\ntraining_function FAILED\n------------------------------------------------------------\nFailures:\n  <NO_OTHER_FAILURES>\n------------------------------------------------------------\nRoot Cause (first observed failure):\n[0]:\n  time      : 2024-12-24_08:44:31\n  host      : worker-7.etched-slurm-worker-svc.etched-slurm.svc.cluster.local\n  rank      : 0 (local_rank: 0)\n  exitcode  : 1 (pid: 200201)\n  error_file: /tmp/torchelastic_7_9x3ers/none_9wcxsstm/attempt_0/0/error.json\n  traceback : Traceback (most recent call last):\n    File \"/home/alex-zhao/.venv/lib/python3.10/site-packages/torch/distributed/elastic/multiprocessing/errors/__init__.py\", line 355, in wrapper\n      return f(*args, **kwargs)\n    File \"/tmp/ipykernel_199646/2341702742.py\", line 2, in training_function\n      accelerator = Accelerator()\n    File \"/home/alex-zhao/.venv/lib/python3.10/site-packages/accelerate/accelerator.py\", line 425, in __init__\n      self.state = AcceleratorState(\n    File \"/home/alex-zhao/.venv/lib/python3.10/site-packages/accelerate/state.py\", line 861, in __init__\n      PartialState(cpu, **kwargs)\n    File \"/home/alex-zhao/.venv/lib/python3.10/site-packages/accelerate/state.py\", line 276, in __init__\n      self.set_device()\n    File \"/home/alex-zhao/.venv/lib/python3.10/site-packages/accelerate/state.py\", line 791, in set_device\n      device_module.set_device(self.device)\n    File \"/home/alex-zhao/.venv/lib/python3.10/site-packages/torch/cuda/__init__.py\", line 478, in set_device\n      torch._C._cuda_setDevice(device)\n    File \"/home/alex-zhao/.venv/lib/python3.10/site-packages/torch/cuda/__init__.py\", line 305, in _lazy_init\n      raise RuntimeError(\n  RuntimeError: Cannot re-initialize CUDA in forked subprocess. To use CUDA with multiprocessing, you must use the 'spawn' start method\n  \n============================================================",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mChildFailedError\u001b[0m                          Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m----> 2\u001b[0m     \u001b[43mnotebook_launcher\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtraining_function\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_processes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m8\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.venv/lib/python3.10/site-packages/accelerate/launchers.py:245\u001b[0m, in \u001b[0;36mnotebook_launcher\u001b[0;34m(function, args, num_processes, mixed_precision, use_port, master_addr, node_rank, num_nodes, rdzv_backend, rdzv_endpoint, rdzv_conf, rdzv_id, max_restarts, monitor_interval, log_line_prefix_template)\u001b[0m\n\u001b[1;32m    243\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m is_torch_version(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m>=\u001b[39m\u001b[38;5;124m\"\u001b[39m, ELASTIC_LOG_LINE_PREFIX_TEMPLATE_PYTORCH_VERSION):\n\u001b[1;32m    244\u001b[0m         launch_config_kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlog_line_prefix_template\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m log_line_prefix_template\n\u001b[0;32m--> 245\u001b[0m     \u001b[43melastic_launch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mLaunchConfig\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mlaunch_config_kwargs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mentrypoint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfunction\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    246\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m ProcessRaisedException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    247\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot re-initialize CUDA in forked subprocess\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m e\u001b[38;5;241m.\u001b[39margs[\u001b[38;5;241m0\u001b[39m]:\n",
      "File \u001b[0;32m~/.venv/lib/python3.10/site-packages/torch/distributed/launcher/api.py:138\u001b[0m, in \u001b[0;36melastic_launch.__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    137\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs):\n\u001b[0;32m--> 138\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mlaunch_agent\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_config\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_entrypoint\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.venv/lib/python3.10/site-packages/torch/distributed/launcher/api.py:269\u001b[0m, in \u001b[0;36mlaunch_agent\u001b[0;34m(config, entrypoint, args)\u001b[0m\n\u001b[1;32m    262\u001b[0m     events\u001b[38;5;241m.\u001b[39mrecord(agent\u001b[38;5;241m.\u001b[39mget_event_succeeded())\n\u001b[1;32m    264\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m result\u001b[38;5;241m.\u001b[39mis_failed():\n\u001b[1;32m    265\u001b[0m         \u001b[38;5;66;03m# ChildFailedError is treated specially by @record\u001b[39;00m\n\u001b[1;32m    266\u001b[0m         \u001b[38;5;66;03m# if the error files for the failed children exist\u001b[39;00m\n\u001b[1;32m    267\u001b[0m         \u001b[38;5;66;03m# @record will copy the first error (root cause)\u001b[39;00m\n\u001b[1;32m    268\u001b[0m         \u001b[38;5;66;03m# to the error file of the launcher process.\u001b[39;00m\n\u001b[0;32m--> 269\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m ChildFailedError(\n\u001b[1;32m    270\u001b[0m             name\u001b[38;5;241m=\u001b[39mentrypoint_name,\n\u001b[1;32m    271\u001b[0m             failures\u001b[38;5;241m=\u001b[39mresult\u001b[38;5;241m.\u001b[39mfailures,\n\u001b[1;32m    272\u001b[0m         )\n\u001b[1;32m    274\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m result\u001b[38;5;241m.\u001b[39mreturn_values\n\u001b[1;32m    275\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m ChildFailedError:\n",
      "\u001b[0;31mChildFailedError\u001b[0m: \n============================================================\ntraining_function FAILED\n------------------------------------------------------------\nFailures:\n  <NO_OTHER_FAILURES>\n------------------------------------------------------------\nRoot Cause (first observed failure):\n[0]:\n  time      : 2024-12-24_08:44:31\n  host      : worker-7.etched-slurm-worker-svc.etched-slurm.svc.cluster.local\n  rank      : 0 (local_rank: 0)\n  exitcode  : 1 (pid: 200201)\n  error_file: /tmp/torchelastic_7_9x3ers/none_9wcxsstm/attempt_0/0/error.json\n  traceback : Traceback (most recent call last):\n    File \"/home/alex-zhao/.venv/lib/python3.10/site-packages/torch/distributed/elastic/multiprocessing/errors/__init__.py\", line 355, in wrapper\n      return f(*args, **kwargs)\n    File \"/tmp/ipykernel_199646/2341702742.py\", line 2, in training_function\n      accelerator = Accelerator()\n    File \"/home/alex-zhao/.venv/lib/python3.10/site-packages/accelerate/accelerator.py\", line 425, in __init__\n      self.state = AcceleratorState(\n    File \"/home/alex-zhao/.venv/lib/python3.10/site-packages/accelerate/state.py\", line 861, in __init__\n      PartialState(cpu, **kwargs)\n    File \"/home/alex-zhao/.venv/lib/python3.10/site-packages/accelerate/state.py\", line 276, in __init__\n      self.set_device()\n    File \"/home/alex-zhao/.venv/lib/python3.10/site-packages/accelerate/state.py\", line 791, in set_device\n      device_module.set_device(self.device)\n    File \"/home/alex-zhao/.venv/lib/python3.10/site-packages/torch/cuda/__init__.py\", line 478, in set_device\n      torch._C._cuda_setDevice(device)\n    File \"/home/alex-zhao/.venv/lib/python3.10/site-packages/torch/cuda/__init__.py\", line 305, in _lazy_init\n      raise RuntimeError(\n  RuntimeError: Cannot re-initialize CUDA in forked subprocess. To use CUDA with multiprocessing, you must use the 'spawn' start method\n  \n============================================================"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    notebook_launcher(training_function, num_processes=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7fa402408f2746c293eecd2e3548dd2b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epochs:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3aee1795bf5a488084ac2a3bd7700f31",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/625 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[5], line 87\u001b[0m, in \u001b[0;36mSANA_VAE.train\u001b[0;34m(self, dataloader, epochs)\u001b[0m\n\u001b[1;32m     85\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m trange(epochs, desc\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEpochs\u001b[39m\u001b[38;5;124m\"\u001b[39m, leave\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[1;32m     86\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m batch \u001b[38;5;129;01min\u001b[39;00m tqdm(dataloader, desc\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBatches\u001b[39m\u001b[38;5;124m\"\u001b[39m, leave\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[0;32m---> 87\u001b[0m         batch \u001b[38;5;241m=\u001b[39m \u001b[43mbatch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     88\u001b[0m         optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[1;32m     89\u001b[0m         output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mforward(batch)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
